<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>Pylon: Programmer&#39;s Guide and API Reference for pylon for Linux</title>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="modified_doxygen-unix.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
</head>
<body>
<div id="TopBanner"><table width="100%"><tr>
    <td width="196px"><img src="Pylon_Logo.png" alt="Pylon Logo" width="196px"></td>
    <td width="99%"></td>
    <td width="184px"><img src="Basler_Logo.png" alt="Basler Logo" width="184px"></td>
</tr></table></div>
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="index.html">pylon C++ Programmer&#39;s Guide for Linux</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Advanced Topics </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><a class="el" href="pylon_advanced_topics.html#architecture">Architecture of pylon</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#buildingapplications">Settings for Building Applications with pylon</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#debugging">Debugging pylon Applications Using GigE Cameras</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#enumerating_and_creating">Enumerating and Creating pylon Devices</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#grab_strategies">Grab Strategies</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#hi_pnp_ref">Getting Informed About Camera Device Removal</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#hi_parsingchunks_ref">Accessing Chunk Features</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#hi_grabbingevents_ref">Handling Camera Events</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#GettingInformedAboutParameterChanges">Getting Informed About Parameter Changes</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#buffer_factory">Instant Camera Class and User Provided Buffers</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#MulticastGrabbing">GigE Multicast/Broadcast: Grab Images of One Camera on Multiple Computers</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#ActionCommand">GigE Action Commands</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#loadsavecamerafeatures">Saving and Restoring Camera Features to/from Files</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#shadingfileio">Transferring Shading Data to the Camera</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#waitingformultiple">Waiting for Multiple Events</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#highperformanceapps">Application Settings for High Performance</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#programmers_guide_low_level_api">Programming Using the pylon Low Level API</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#migration_to_usb">Migrating Existing Code for Using SFNC 2.x-Based Camera Devices</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#sfnc_parameter_name_changes_cm">Migration Mode</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#camemu_tl">Camera Emulator</a> </li>
<li><a class="el" href="pylon_advanced_topics.html#decompression">Image Decompression</a></li>
</ul>
<p>The advanced topics section can be consulted if more information about special use cases is required.</p>
<h1><a class="anchor" id="architecture"></a>
Architecture of pylon</h1>
<p>This section gives a short introduction to the most important concepts of the pylon C++ API.</p>
<div class="image">
<img src="pylon3_0_cpp_api.png" alt="pylon3_0_cpp_api.png"/>
<div class="caption">
The pylon C++ API</div></div>
 <h2><a class="anchor" id="TransportLayers"></a>
Transport Layers</h2>
<p>The term 'transport layer' is used as an abstraction for a physical interface such as USB, GigE, or Camera Link. For each of these interfaces, there are drivers providing access to camera devices. pylon currently includes several different transport layers: </p><ul>
<li>BaslerGigE for Gigabit Ethernet cameras using the GigE Vision protocol </li>
<li>BaslerUsb for USB3 Vision-compliant cameras </li>
<li>BaslerCameraLink for Camera Link cameras using the CL serial interface (limited to camera configuration only; not available on Linux and macOS platforms)</li>
</ul>
<p><a class="el" href="struct_pylon_1_1_i_transport_layer.html">Transport Layer objects</a> are <a class="el" href="class_pylon_1_1_c_tl_factory.html">device factories</a> and are used to: </p><ul>
<li>Discover devices (this process is also called device enumeration) </li>
<li>Create pylon Devices used to access camera devices </li>
<li>Destroy pylon Devices </li>
<li>Access transport layer specific parameters</li>
</ul>
<h2><a class="anchor" id="TransportLayerFactory"></a>
Transport Layer Factory</h2>
<p>An application program does not access transport layer implementations directly. The Transport Layer Factory is used to create Transport Layer objects, each of which represents a transport layer. Additionally, the <a class="el" href="class_pylon_1_1_c_tl_factory.html">Transport Layer Factory</a> can be used as a <a class="el" href="class_pylon_1_1_c_tl_factory.html">device factory</a> to create and destroy pylon Devices for all transport layers.</p>
<h2><a class="anchor" id="GenApiNodeMaps"></a>
GenApi Node Maps</h2>
<p>For camera configuration and for accessing other parameters, the pylon API uses the technologies defined by the GenICam standard hosted by the European Machine Vision Association (EMVA). The GenICam specification (<a href="http://www.GenICam.org">http://www.GenICam.org</a>) defines a format for camera description files. These files describe the configuration interface of GenICam compliant cameras. The description files are written in XML (eXtensible Markup Language) and describe camera registers, their interdependencies, and all other information needed to access high-level features such as <code>Gain</code>, <code>Exposure</code> <code>Time</code>, or <code>Image</code> <code>Format</code> by means of low level register read and write operations.</p>
<p>The elements of a camera description file are represented as software objects called Nodes. For example, a node can represent a single camera register, a camera parameter such as Gain, a set of available parameter values, etc. Each node implements the <code><a class="el" href="struct_gen_api_1_1_i_node.html" title="Interface common to all nodes. ">GenApi::INode</a></code> interface.</p>
<p>The nodes are linked together by different relationships as explained in the GenApi standard document available at www.GenICam.org. The complete set of nodes is stored in a data structure called node map. At runtime, a node map is instantiated from an XML description.</p>
<p>In pylon, node maps are not only used to represent camera device parameters. Parameters of other pylon objects such as Transport Layer objects or the Image Format Converter are also exposed via GenApi node maps.</p>
<p>Examples:</p>
<ul>
<li>The <code><a class="el" href="class_pylon_1_1_c_instant_camera.html" title="Provides convenient access to a camera device. ">Pylon::CInstantCamera</a></code> class has the <code><a class="el" href="class_pylon_1_1_c_instant_camera.html#a3227195969200a52200364bf31e9c586" title="Provides access to the node map of the camera device. ">Pylon::CInstantCamera::GetNodeMap()</a></code> method, which returns the node map containing all GenApi nodes representing the whole set of camera parameters. </li>
<li>The <code><a class="el" href="class_pylon_1_1_c_image_format_converter.html#a78b2bec7fb5867f833b91774b55b7a13" title="Provides access to the node map of the format converter. ">Pylon::CImageFormatConverter::GetNodeMap()</a></code> method is used to access the Image Format Converter's parameters.</li>
</ul>
<h2><a class="anchor" id="LowLevelAPIObjects"></a>
Low Level API</h2>
<p>All transport layers implement the Low Level API interface. This means that for all transport layers, things can be handled in the same way. The <a class="el" href="group___pylon___low_level_api.html">Low Level API</a> section lists all Low Level API classes.</p>
<h3><a class="anchor" id="CameraObjects"></a>
Low Level API pylon Devices</h3>
<p>In pylon, physical camera devices are represented by <a class="el" href="struct_pylon_1_1_i_pylon_device.html">pylon Devices</a>.</p>
<h3><a class="anchor" id="StreamGrabbers"></a>
Stream Grabbers</h3>
<p>The pylon architecture allows a camera object to deliver one or more streams of image data. To grab images from a stream, a stream grabber object is required. Stream grabber objects can't be created directly by an application. They are managed by camera objects.</p>
<h3><a class="anchor" id="EventGrabbersSubSub"></a>
Event Grabbers</h3>
<p>Basler GigE Vision and USB3 Vision cameras can send event messages. Event Grabber objects are used to receive event messages.</p>
<h3><a class="anchor" id="ChunkParsers"></a>
Chunk Parsers</h3>
<p>If the so-called Chunk Mode is activated, Basler Cameras can send additional information appended to the image data. When in Chunk Mode, the camera sends an extended data stream which consists of image data and additional information such as a frame number or a time stamp. The extended data stream is self-descriptive. pylon Chunk Parser objects are used for parsing the extended data stream and for providing access to the added information.</p>
<h2><a class="anchor" id="InstantCameraObjects"></a>
Instant Camera Classes</h2>
<p>An <a class="el" href="class_pylon_1_1_c_instant_camera.html">Instant Camera </a> provides convenient access to a camera device while being highly customizable. It allows to grab images with few lines of code providing instant access to grabbed images from a camera device. Internally a pylon Device is used. A pylon Device needs to be created and attached to the Instant Camera object for operation. The additional <a class="el" href="class_pylon_1_1_c_basler_universal_instant_camera.html"><code>CBaslerUniversalInstantCamera</code> </a> class provides more convenient access to the parameters of the camera. Furthermore, the <a class="el" href="pylon_programmingguide.html#hi_instant_camera_array">Instant Camera Array classes</a> ease programming for image grabbing from multiple camera devices.</p>
<h2><a class="anchor" id="hi_image_handling_architecture"></a>
Image Handling Support</h2>
<p>Besides the Instant Camera classes used for grabbing images pylon offers additional <a class="el" href="group___pylon___image_handling_support.html">Image Handling Support</a> support for handling grabbed images. There are an image class, an image format converter, and the loading and saving of images.</p>
<h1><a class="anchor" id="buildingapplications"></a>
Settings for Building Applications with pylon</h1>
<p>As described in <a class="el" href="pylon_programmingguide.html#buildingapplications_brief">Building Applications with pylon</a>, you can use the <code>pylon-config</code> utility to get all the parameters required to build applications based on pylon.</p>
<h2><a class="anchor" id="linkeroptions"></a>
Required Linker Options</h2>
<p>Executables using the pylon API <b>must</b> be linked using the <code>-Wl,-E</code> compiler option. This option is automatically provided by <code>pylon-config &amp;ndash;libs</code>. It ensures that run-time type information for pylon-defined types is processed properly. This is essential for proper exception handling and dynamic casting of objects.</p>
<h2><a class="anchor" id="rpathlink"></a>
Locating dependencies using RPATH</h2>
<p>At runtime, the dynamic linker must know where it can find the pylon libraries. In pylon versions prior to 5.0 this was handled by extending the environment variable &lt;LD_LIBRARY_PATH&gt;. This works, but it is a rather cumbersome and error prone.</p>
<p>From pylon 5 upwards, we use the rpath feature of the GNU linker to specify the runtime location of pylon. You can find more details about rpath and runpath at <a href="https://en.wikipedia.org/wiki/Rpath">https://en.wikipedia.org/wiki/Rpath</a>.</p>
<p>There are two cases to distinguish when you want to build an application with rpath support: </p><dl class="section note"><dt>Note</dt><dd>These snippets assume, that the environment variable &lt;PYLON_ROOT&gt; points to your pylon installation (e.g. /opt/pylon6).</dd></dl>
<ul>
<li><b>Case 1:</b> The location of the pylon install is the same at compile time and runtime. In this case you can use: <div class="fragment"><div class="line">LDFLAGS    += $(shell $(PYLON_ROOT)/bin/pylon-config --libs-rpath)</div></div><!-- fragment --></li>
</ul>
<ul>
<li><b>Case 2:</b> The location of the pylon install at runtime differs from the compile time location. In this case, you'll want to supply the rpath for the runtime, but the linker must still be able to resolve second-level dependencies at compile time. For this to work, we added the <code>&amp;ndash</code>;libs-rpath-link option to <code>pylon-config</code> <div class="fragment"><div class="line">LDFLAGS   += -Wl,-rpath,/runtime/pylon/install/dir</div><div class="line">LDFLAGS   += $(shell $(PYLON_ROOT)/bin/pylon-config --libs-rpath-link)</div></div><!-- fragment --></li>
</ul>
<h1><a class="anchor" id="debugging"></a>
Debugging pylon Applications Using GigE Cameras</h1>
<p>When debugging a pylon application using GigE cameras you may encounter heartbeat timeouts. The application must send special network packets to the camera in defined intervals. If the camera doesn't receive these heartbeats it will consider the connection as broken and won't accept any commands from the application.</p>
<p>When you run your application pylon will normally generate these heartbeats. When you set a breakpoint in your application and the breakpoint is hit, the debugger will suspend all threads including the one sending the heartbeats. So when you debug your application and single step through your code no heartbeats are sent to the camera.</p>
<p>To work around this you have to extend the heartbeat timeout during development. You can do this by setting an environment variable named &lt;PYLON_GIGE_HEARTBEAT&gt; which will instruct pylon to set the heartbeat interval when opening the camera or you can set the heartbeat timeout value named "HeartbeatTimeout" of the camera transport layer in your code. To set the environment variable set an environment variable named &lt;PYLON_GIGE_HEARTBEAT&gt; and set its value to the desired timeout in milliseconds.</p>
<p>To set the Heartbeat timeout in code set the value on the <code>HeartbeatTimeout</code> node of the transport layer: </p><div class="fragment"><div class="line"><span class="comment">// retrieve the heartbeat node from the transport layer node map</span></div><div class="line">CIntegerParameter heartbeat(camera.GetTLNodeMap(), <span class="stringliteral">&quot;HeartbeatTimeout&quot;</span>);</div><div class="line"><span class="comment">// set heartbeat to 600 seconds. (Note: Only GigE cameras have a &quot;HeartbeatTimeout&quot; node)</span></div><div class="line">heartbeat.TrySetValue(600*1000);</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>When you set the heartbeat to a high value and stop your application without closing the device properly by calling the Close function you won't be able to open the camera again and will receive an error stating the device is currently in use. This can happen if you stop your application using the debugger. To open the camera again you must either wait until the timeout elapses or disconnect the network cable from the camera.</dd>
<dd>
The pylon GigE transport layer automatically sets the heartbeat timeout to 5 minutes when creating a device if running under a debugger. This can be overridden by setting the PYLON_GIGE_HEARTBEAT environment variable. We recommend not to rely on the default mechanism but to explicitly specify the heartbeat timeout by setting the environment variable or by setting an appropriate heartbeat timeout in the application.</dd></dl>
<h1><a class="anchor" id="enumerating_and_creating"></a>
Enumerating and Creating pylon Devices</h1>
<p>pylon offers two ways to enumerate and create pylon Devices. The first approach uses the Transport Layer Factory to enumerate cameras across multiple transport layers. The second approach lets a Transport Layer object enumerate and create pylon Devices for a specific transport layer. Before describing the different enumeration schemes, the terms Device Class and Device Info object are introduced.</p>
<h2><a class="anchor" id="DeviceClasses"></a>
Device Classes</h2>
<p>Each transport layer can create a specific type of pylon Device. For example, the PylonGigE transport layer will create pylon Devices representing GigE Vision cameras. Each type of device is associated with a unique identifier string called Device Class. The device class identifier can be found in the <a class="el" href="_device_class_8h.html" title="Device class definitions. ">DeviceClass.h</a> header file.</p>
<h2><a class="anchor" id="DeviceInfoObjects"></a>
Device Info Objects</h2>
<p>The device enumeration procedure returns a list of Device Info objects. The base class for Device Info objects is <code><a class="el" href="class_pylon_1_1_c_device_info.html" title="Holds information about an enumerated device. ">Pylon::CDeviceInfo</a></code>. A Device Info object uniquely describes a camera device. Device Info objects are used by a Transport Layer and the Transport Layer Factory to create camera objects representing the device described by the Device Info objects.</p>
<p>A <code><a class="el" href="class_pylon_1_1_c_device_info.html" title="Holds information about an enumerated device. ">Pylon::CDeviceInfo</a></code> object stores a set of string properties. The data type of the values is <code><a class="el" href="namespace_pylon.html#a243b4b164b22d387ffd02a9ed20f15b9" title="Pylon&#39;s string definition. ">Pylon::String_t</a></code>. The following properties are available for all Device Info Objects:</p>
<table  border="1" class="table" frame="void" cellspacing="6" cellpadding="7">
<tr>
<th>Name</th><th>Description </th></tr>
<tr>
<td>FriendlyName </td><td>A human readable name for the device (e.g. the camera's model name). Friendly names are not unique.  </td></tr>
<tr>
<td>FullName </td><td>A unique identifier for the device. No two devices will have the same full name.  </td></tr>
<tr>
<td>VendorName </td><td>The name of the vendor.  </td></tr>
<tr>
<td>DeviceClass </td><td>Each transport layer can create a specific type (or class) of camera devices (e.g., USB or GigE Vision devices). The device types are identified by the Device Class property. </td></tr>
<tr>
<td>SerialNumber </td><td>The device's serial number. The availability of the device serial number is not guaranteed during the enumeration process, so the Serial Number Property may be undefined.  </td></tr>
<tr>
<td>UserDefinedName </td><td>For some device classes, it is possible to assign a user defined name to a camera device. The value of this property is not necessarily unique.  </td></tr>
<tr>
<td>DeviceFactory </td><td>The unique full name of the Transport Layer object that can create the device. </td></tr>
</table>
<p>In addition, specific transport layers will require additional properties. These properties can be accessed in a generic way by using the <code><a class="el" href="struct_pylon_1_1_i_properties.html" title="interface for a property container ">Pylon::IProperties</a></code> interface.</p>
<p>A more comfortable way is downcasting a Device Info object to the concrete class. This is illustrated in the following example, which prints out the IP address of a GigE Device Info object: </p><div class="fragment"><div class="line">CBaslerGigECamera::DeviceInfo_t&amp; GigEDeviceInfo =</div><div class="line">  <span class="keyword">static_cast&lt;</span>CBaslerGigECamera::DeviceInfo_t&amp;<span class="keyword">&gt;</span>(DeviceInfo);</div><div class="line">cout &lt;&lt; GigEDeviceInfo.GetIpAddress() &lt;&lt; endl;</div></div><!-- fragment --><h2><a class="anchor" id="UsingTlFactory"></a>
Using the Transport Layer Factory for Enumerating Cameras</h2>
<p>The <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#a9a66b37caea9bbd0a50cf377ba4ed94a" title="Retrieves a list of available devices. ">Pylon::CTlFactory::EnumerateDevices()</a></code> method is used to retrieve a list of all available devices, regardless of which transport layer is used to access the device. The list contains Device Info objects that must be used for creating Camera objects.</p>
<p>The returned lists are of the <code><a class="el" href="namespace_pylon.html#a7df1a09a012dcec35092f3a732101af7" title="STL std::vector like container for Pylon::CDeviceInfo objects. ">Pylon::DeviceInfoList_t</a></code> type and are used similarly to the C++ Standard Library <code>std::vector</code> class.</p>
<p>The following example prints out the unique names of all connected devices: </p><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;ostream&gt;</span></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespace_pylon.html">Pylon</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main()</div><div class="line">{</div><div class="line">  <a class="code" href="class_pylon_1_1_pylon_auto_init_term.html">PylonAutoInitTerm</a> autoInitTerm;</div><div class="line"></div><div class="line">  <a class="code" href="class_pylon_1_1_c_tl_factory.html">CTlFactory</a>&amp; TlFactory = <a class="code" href="class_pylon_1_1_c_tl_factory.html#a1d3fbd0bb73b4acd88de7cff893554ab">CTlFactory::GetInstance</a>();</div><div class="line">  <a class="code" href="class_pylon_1_1_device_info_list.html">DeviceInfoList_t</a> lstDevices;</div><div class="line">  TlFactory.<a class="code" href="class_pylon_1_1_c_tl_factory.html#a9a66b37caea9bbd0a50cf377ba4ed94a">EnumerateDevices</a>( lstDevices );</div><div class="line">  <span class="keywordflow">if</span> ( ! lstDevices.empty() ) {</div><div class="line">    DeviceInfoList_t::const_iterator it;</div><div class="line">    <span class="keywordflow">for</span> ( it = lstDevices.begin(); it != lstDevices.end(); ++it )</div><div class="line">      cout &lt;&lt; it-&gt;GetFullName();</div><div class="line">  }</div><div class="line">  <span class="keywordflow">else</span></div><div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;No devices found!&quot;</span> &lt;&lt; endl;</div><div class="line"></div><div class="line">  <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p>The Transport Layer Factory provides a Device Info object and can be used to create Camera objects. The following example illustrates how to create a Camera object for the first element in the device list: </p><div class="fragment"><div class="line">IPylonDevice *pDevice = TlFactory.<a class="code" href="class_pylon_1_1_c_tl_factory.html#a5bfdb71c0f2ffd0d86839b8f463c3c4d">CreateDevice</a>( lstDevices[0] );</div></div><!-- fragment --><dl class="section attention"><dt>Attention</dt><dd>Never call <code>free</code> or <code>delete</code> on a <code><a class="el" href="struct_pylon_1_1_i_pylon_device.html" title="Low Level API: Interface for camera objects. ">Pylon::IPylonDevice</a></code> pointer created by the Transport Layer Factory. Instead, use the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#ae1f2e7bcf55bf64162f356d4b749f5b6" title="Destroys a device. ">Pylon::CTlFactory::DestroyDevice()</a></code> method to delete an IPylonDevice pointer.</dd></dl>
<h2><a class="anchor" id="CreatingTls"></a>
Using the Transport Layer Factory to Create a Transport Layer</h2>
<p>A list of all available transport layers can be retrieved by calling the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#adc34e0b7ba65baa624723f6ea27b6f7f" title="Retrieves a list of available transport layers. ">Pylon::CTlFactory::EnumerateTls()</a></code> method. This method fills a list with Transport Layer Info objects (<code><a class="el" href="class_pylon_1_1_c_tl_info.html" title="Class used for storing the result of the transport layer enumeration process. ">Pylon::CTlInfo</a></code>). The data structures are very similar to Device Info objects. Transport Layer Info objects are used as arguments for the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#a46dcaa7cf07b96fd9fae2583bf65266a" title="Creates a transport layer object from a transport layer info object. ">Pylon::CTlFactory::CreateTl()</a></code> method that creates Transport Layer objects. The method returns a pointer of the <code><a class="el" href="struct_pylon_1_1_i_transport_layer.html" title="The interface of Transport Layer objects. ">Pylon::ITransportLayer</a></code> type.</p>
<dl class="section attention"><dt>Attention</dt><dd>Never call <code>free</code> or <code>delete</code> on a ITransportLayer pointer created by the Transport Layer Factory. Instead, use the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#a310a6c7143529e19101f959a605d77b9" title="Releases a transport layer object created by a call to CreateTl(). ">Pylon::CTlFactory::ReleaseTl()</a></code> method to free Transport Layer objects.</dd></dl>
<h2><a class="anchor" id="UsingTlos"></a>
Using a Transport Layer Object for Enumerating Cameras</h2>
<p>Transport Layer objects can be used to enumerate all devices accessible by a specific transport layer. Transport Layer objects are created by the Transport Layer Factory. This is illustrated in the following example, which creates a Transport Layer object for the PylonGigE transport layer: </p><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;pylon/gige/BaslerGigECamera.h&gt;</span></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespace_pylon.html">Pylon</a>;</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main()</div><div class="line">{</div><div class="line">  <a class="code" href="class_pylon_1_1_pylon_auto_init_term.html">PylonAutoInitTerm</a> autoInitTerm;</div><div class="line"></div><div class="line">  <a class="code" href="class_pylon_1_1_c_tl_factory.html">CTlFactory</a>&amp; TlFactory = <a class="code" href="class_pylon_1_1_c_tl_factory.html#a1d3fbd0bb73b4acd88de7cff893554ab">CTlFactory::GetInstance</a>();</div><div class="line">  <a class="code" href="struct_pylon_1_1_i_transport_layer.html">ITransportLayer</a>* pTl</div><div class="line">    = TlFactory.<a class="code" href="class_pylon_1_1_c_tl_factory.html#a46dcaa7cf07b96fd9fae2583bf65266a">CreateTl</a>( CBaslerGigECamera::DeviceClass() );</div><div class="line"></div><div class="line">  <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p>As described above, Transport Layer objects can also be created by passing in a Transport Layer Info object.</p>
<p>The Transport Layer Object is now used for enumerating all of the devices it can access: </p><div class="fragment"><div class="line"><a class="code" href="namespace_pylon.html#a7df1a09a012dcec35092f3a732101af7">DeviceInfoList_t</a> lstDevices;</div><div class="line">pTl-&gt;<a class="code" href="struct_pylon_1_1_i_device_factory.html#a7c9485beb3f38fc1c17929a46f6bb7a2">EnumerateDevices</a>( lstDevices );</div><div class="line"><span class="keywordflow">if</span> ( lstDevices.empty() ) {</div><div class="line">    cerr &lt;&lt;  <span class="stringliteral">&quot;No devices found&quot;</span> &lt;&lt; endl;</div><div class="line">    exit(1);</div><div class="line">}</div></div><!-- fragment --><p><code><a class="el" href="struct_pylon_1_1_i_device_factory.html#a7c9485beb3f38fc1c17929a46f6bb7a2" title="Retrieves a list of available devices. ">Pylon::ITransportLayer::EnumerateDevices</a></code> adds the discovered devices to the passed-in Device Info List.</p>
<p>The Transport Layer object is now used for creating a Camera object. In the following example, a Camera Object for the first enumerated camera device is created: </p><div class="fragment"><div class="line">IPylonDevice* pDevice = pTl-&gt;<a class="code" href="struct_pylon_1_1_i_device_factory.html#a9891f54248fa6dc0f7cab171044458c4">CreateDevice</a>( lstDevices[0] );</div></div><!-- fragment --><dl class="section attention"><dt>Attention</dt><dd>Never call <code>free</code> or <code>delete</code> on a <code><a class="el" href="struct_pylon_1_1_i_pylon_device.html" title="Low Level API: Interface for camera objects. ">Pylon::IPylonDevice</a></code> pointer created by the Transport Layer Factory. Instead, use the <code><a class="el" href="class_pylon_1_1_c_tl_factory.html#ae1f2e7bcf55bf64162f356d4b749f5b6" title="Destroys a device. ">Pylon::CTlFactory::DestroyDevice()</a></code> method to delete an IPylonDevice pointer.</dd></dl>
<h2><a class="anchor" id="UsingEnumeraionWithFilter"></a>
Applying a Filter when Enumerating Cameras</h2>
<p>For enumerating a range of devices that have certain properties the EnumerateDevices method applying a filter can be used. To define the properties a filter list with device info objects can be passed. A camera is enumerated if it has the properties of at least one device info object in the filter list. The following example enumerates all cameras with the model names in the filter list.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;ostream&gt;</span></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespace_pylon.html">Pylon</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main()</div><div class="line">{</div><div class="line">  <a class="code" href="class_pylon_1_1_pylon_auto_init_term.html">PylonAutoInitTerm</a> autoInitTerm;</div><div class="line"></div><div class="line">  <a class="code" href="class_pylon_1_1_c_tl_factory.html">CTlFactory</a>&amp; TlFactory = <a class="code" href="class_pylon_1_1_c_tl_factory.html#a1d3fbd0bb73b4acd88de7cff893554ab">CTlFactory::GetInstance</a>();</div><div class="line"></div><div class="line">  <a class="code" href="class_pylon_1_1_device_info_list.html">DeviceInfoList_t</a> filter;</div><div class="line">  filter.push_back( <a class="code" href="class_pylon_1_1_c_device_info.html">CDeviceInfo</a>().SetModelName( <span class="stringliteral">&quot;SCA750-60FC&quot;</span>));</div><div class="line">  filter.push_back( <a class="code" href="class_pylon_1_1_c_device_info.html">CDeviceInfo</a>().SetModelName( <span class="stringliteral">&quot;SCA780-54FC&quot;</span>));</div><div class="line"></div><div class="line">  <a class="code" href="class_pylon_1_1_device_info_list.html">DeviceInfoList_t</a> lstDevices;</div><div class="line">  TlFactory.<a class="code" href="class_pylon_1_1_c_tl_factory.html#a9a66b37caea9bbd0a50cf377ba4ed94a">EnumerateDevices</a>( lstDevices, filter );</div><div class="line">  <span class="keywordflow">if</span> ( ! lstDevices.empty() ) {</div><div class="line">    DeviceInfoList_t::const_iterator it;</div><div class="line">    <span class="keywordflow">for</span> ( it = lstDevices.begin(); it != lstDevices.end(); ++it )</div><div class="line">      cout &lt;&lt; it-&gt;GetFullName();</div><div class="line">  }</div><div class="line">  <span class="keywordflow">else</span></div><div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;No devices found!&quot;</span> &lt;&lt; endl;</div><div class="line"></div><div class="line">  <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><h2><a class="anchor" id="CreatingSpecificDevices"></a>
Creating Specific Cameras</h2>
<p>For creating a specific device an info object must be set up with the properties of the desired device. In the following example the serial number and the transport layer type are used for identifying the camera. Specifying the transport layer limits the search to the correct transport layer. This saves computation time when using the transport layer factory.</p>
<div class="fragment"><div class="line">CTlFactory&amp; TlFactory = CTlFactory::GetInstance();</div><div class="line"></div><div class="line">CDeviceInfo di;</div><div class="line">di.SetSerialNumber( <span class="stringliteral">&quot;20399956&quot;</span> );</div><div class="line">di.SetTLType( <a class="code" href="namespace_pylon_1_1_t_l_type.html#a9ef921e82f6c1842290d71ec082dceed">TLType::TLTypeUSB</a> );</div><div class="line">IPylonDevice* device = TlFactory.CreateDevice( di );</div></div><!-- fragment --><p>The above example can also be written in one line:</p>
<div class="fragment"><div class="line">IPylonDevice* device = CTlFactory::GetInstance().CreateDevice( CDeviceInfo().SetTLType( <a class="code" href="namespace_pylon_1_1_t_l_type.html#a9ef921e82f6c1842290d71ec082dceed">TLType::TLTypeUSB</a> ).SetSerialNumber( <span class="stringliteral">&quot;20399956&quot;</span> ));</div></div><!-- fragment --><p>The CreateDevice method will fail when multiple devices match the provided properties. If it is required to create any one of multiple devices the CreateFirstDevice method can be used.</p>
<p>The following sample illustrates how to create a device object for a GigE camera with a specific IP address:</p>
<div class="fragment"><div class="line"><span class="preprocessor">    #include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div><div class="line"><span class="preprocessor">    #include &lt;pylon/gige/PylonGigEIncludes.h&gt;</span></div><div class="line"></div><div class="line"><span class="comment">//....</span></div><div class="line"></div><div class="line">    CTlFactory&amp; TlFactory = CTlFactory::GetInstance();</div><div class="line">    CBaslerGigEDeviceInfo di;</div><div class="line">    di.SetIpAddress( <span class="stringliteral">&quot;192.168.0.101&quot;</span>);</div><div class="line">    IPylonDevice* device = TlFactory.CreateDevice( di);</div></div><!-- fragment --><h1><a class="anchor" id="grab_strategies"></a>
Grab Strategies</h1>
<p>The following grab strategies involve the triggering of the camera device. Depending on the cofiguration of the camera device the following trigger modes are supported.</p>
<ul>
<li>An external trigger, e.g. via digital I/O </li>
<li>A software trigger command </li>
<li>An internal trigger (so-called free running mode).</li>
</ul>
<p>Additional information regarding this topic can be found in the code sample <a class="el" href="sample_code.html#sample_Grab_Strategies">Grab_Strategies</a> and in the parameter documentation of the <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params.html">Instant Camera </a>.</p>
<h2><a class="anchor" id="grab_strategy_one_by_one"></a>
One by One Grab Strategy</h2>
<div class="image">
<img src="pylon_buffer_flow_one_by_one.png" alt="pylon_buffer_flow_one_by_one.png"/>
<div class="caption">
The Buffer Flow Using the One by One Grab Strategy</div></div>
<p> When the One by One grab strategy is used images are processed in the order of their acquisition.</p>
<ul>
<li>The Instant Camera grab engine unqueues buffers from the Empty Buffer Queue and queues the empty buffers at the Low Level API stream grabber (1). </li>
<li>The camera device is triggered (2). An image is acquired by the camera device, the image is transfered to the computer and then grabbed into an empty buffer. </li>
<li>The Instant Camera grab engine thread is notified that a filled buffer is available. The filled buffer is retrieved by the grab engine thread (3) and it is put into the Output Queue. </li>
<li>The application thread waiting inside the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3af3b05b85ea0aeb68eb5fb1b6dba0c8">RetrieveResult() </a> method is notified, it stops waiting for a grab result, and it retrieves the filled buffer (4) as part of a grab result data object. </li>
<li>The grab result data object is held by a grab result smart pointer. After the application has processed the image data the filled buffer is returned to the Empty Buffer Queue (5). This is done by the grab result smart pointer destuctor or when the grab result data object is explicitly released. Returned buffers are used again for grabbing.</li>
</ul>
<h2><a class="anchor" id="grab_strategy_latest_image_only"></a>
Latest Image Only Grab Strategy</h2>
<div class="image">
<img src="pylon_buffer_flow_latest.png" alt="pylon_buffer_flow_latest.png"/>
<div class="caption">
The Buffer Flow Using the Latest Image Only Grab Strategy</div></div>
<p>The Latest Image Only grab strategy differs from the One By One grab strategy by the size of the Output Queue. The size of the output queue is only 1 buffer. If a new buffer has been grabbed and there is already a buffer waiting in the Output Queue then the buffer waiting in the output queue is automatically returned to the Empty Buffer Queue (4.1). The newly filled buffer is then placed into the output queue. This assures that always the latest grabbed image is provided to the application. Images that are automatically returned to the Empty Buffer Queue are called skipped images.</p>
<h2><a class="anchor" id="grab_strategy_latest_images"></a>
Latest Images Strategy</h2>
<div class="image">
<img src="pylon_buffer_flow_latest.png" alt="pylon_buffer_flow_latest.png"/>
<div class="caption">
The Buffer Flow Using the Latest Images Grab Strategy</div></div>
<p>The Latest Images strategy extends the above strategies. It allows the user to adjust the size of Output Queue by setting <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params__v6__1__0.html#a36d1fe2d22ff3a2f21fda6e568049e07"><code>CInstantCamera::OutputQueueSize</code> </a>. If a new buffer has been grabbed and the output queue is full, the first buffer waiting in the output queue is automatically returned to the Empty Buffer Queue (4.1). The newly filled buffer is then placed into the output queue. This ensures that the application is always provided with the latest grabbed images. Images that are automatically returned to the Empty Buffer Queue are called skipped images. When setting the output queue size to 1, this strategy is equivalent to Latest Image Only grab strategy. When setting the output queue size to CInstantCamera::MaxNumBuffer, this strategy is equivalent to One By One grab strategy.</p>
<h2><a class="anchor" id="grab_strategy_upcoming_image"></a>
Upcoming Image Grab Strategy</h2>
<div class="image">
<img src="pylon_buffer_flow_upcoming.png" alt="pylon_buffer_flow_upcoming.png"/>
<div class="caption">
The Buffer Flow Using the Upcoming Image Grab Strategy</div></div>
<p>The Upcoming Image grab strategy can be used to make sure to get an image that has been grabbed after RetrieveResult() has been called.</p>
<ul>
<li>The Low Level API stream grabber does not receive empty buffers until RetrieveResult() is called. When the application calls RetrieveResult() (1), one empty buffer is unqueued from the Empty Buffer Queue and the empty buffer is then passed to the Low Level API stream grabber (2). </li>
<li>The camera device is triggered (3). An image is acquired by the camera device, it is transfered to the computer and grabbed into the empty buffer. </li>
<li>The now filled buffer is then returned as part of a grab result data object held by a grab result smart pointer (4)(1). </li>
<li>After the application has processed the image data the filled buffer is returned to the Empty Buffer Queue (5). This is done by the grab result smart pointer destuctor or when the grab result data object is explicitly released. If the RetrieveResult() timeout times out the empty buffer is returned to the Empty Buffer Queue.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>The grab strategy Upcoming Image can't be used together with USB camera devices. See section <a class="el" href="pylon_advanced_topics.html#usb_changes_transport">Differences in Image Transport</a> and the following section for more information.</dd></dl>
<h1><a class="anchor" id="hi_pnp_ref"></a>
Getting Informed About Camera Device Removal</h1>
<p>To get informed about camera device removal the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3bc410c61618d7565455751991ce2791"><code>IsCameraDeviceRemoved()</code> </a> method can be queried or a <a class="el" href="pylon_programmingguide.html#hi_eventhandler_configurations">configuration event handler</a> can be registered. The virtual <a class="el" href="class_pylon_1_1_c_configuration_event_handler.html#afe121efea7306bb5f3d0b8a958d82677"><code>OnCameraDeviceRemoved()</code> </a> method is called if a camera device is removed. The device removal is only detected while the Instant Camera and therefore the attached pylon Device are open. The attached pylon Device needs to be destroyed after a device removal. This can be done using the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a5d30e0748815f30d3ef4836facb8795a"><code>DestroyDevice()</code> </a> method.</p>
<p>The following is an example of a configuration event handler that is handling camera device removal:</p>
<div class="fragment"><div class="line"><span class="comment">//Example of a configuration event handler that handles device removal events.</span></div><div class="line"><span class="keyword">class </span>CSampleConfigurationEventHandler : <span class="keyword">public</span> <a class="code" href="class_pylon_1_1_c_configuration_event_handler.html">Pylon::CConfigurationEventHandler</a></div><div class="line">{</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="comment">// This method is called from a different thread when the camera device removal has been detected.</span></div><div class="line">    <span class="keywordtype">void</span> <a class="code" href="class_pylon_1_1_c_configuration_event_handler.html#afe121efea7306bb5f3d0b8a958d82677">OnCameraDeviceRemoved</a>( CInstantCamera&amp; <span class="comment">/*camera*/</span>)</div><div class="line">    {</div><div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;CSampleConfigurationEventHandler::OnCameraDeviceRemoved called.&quot;</span> &lt;&lt; std::endl;</div><div class="line">    }</div><div class="line">};</div></div><!-- fragment --><p>The following example shows how a device removal is detected while the camera is accessed in a loop. The <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3bc410c61618d7565455751991ce2791"><code>IsCameraDeviceRemoved()</code> </a> method can be used to check whether the removal of the camera device has caused an exception while accessing the camera device, e.g. for grabbing.</p>
<div class="fragment"><div class="line"><span class="comment">// Declare a local counter used for waiting.</span></div><div class="line"><span class="keywordtype">int</span> loopCount = 0;</div><div class="line"></div><div class="line"><span class="comment">// Get the transport layer factory.</span></div><div class="line">CTlFactory&amp; tlFactory = CTlFactory::GetInstance();</div><div class="line"></div><div class="line"><span class="comment">// Create an instant camera object with the camera device found first.</span></div><div class="line">CInstantCamera camera( tlFactory.CreateFirstDevice());</div><div class="line"></div><div class="line"><span class="comment">// Print the camera information.</span></div><div class="line">cout &lt;&lt; <span class="stringliteral">&quot;Using device &quot;</span> &lt;&lt; camera.GetDeviceInfo().GetModelName() &lt;&lt; endl;</div><div class="line">cout &lt;&lt; <span class="stringliteral">&quot;Friendly Name: &quot;</span> &lt;&lt; camera.GetDeviceInfo().GetFriendlyName() &lt;&lt; endl;</div><div class="line">cout &lt;&lt; <span class="stringliteral">&quot;Full Name    : &quot;</span> &lt;&lt; camera.GetDeviceInfo().GetFullName() &lt;&lt; endl;</div><div class="line">cout &lt;&lt; <span class="stringliteral">&quot;SerialNumber : &quot;</span> &lt;&lt; camera.GetDeviceInfo().GetSerialNumber() &lt;&lt; endl;</div><div class="line">cout &lt;&lt; endl;</div><div class="line"></div><div class="line"><span class="comment">// For demonstration purposes only, register another configuration event handler that handles device removal.</span></div><div class="line">camera.RegisterConfiguration( <span class="keyword">new</span> CSampleConfigurationEventHandler, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5a33cc17aa219c33ea966e987b906cd364">Cleanup_Delete</a>);</div><div class="line"></div><div class="line"><span class="comment">// For demonstration purposes only, add a sample configuration event handler to print out information</span></div><div class="line"><span class="comment">// about camera use.</span></div><div class="line">camera.RegisterConfiguration( <span class="keyword">new</span> CConfigurationEventPrinter, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5a33cc17aa219c33ea966e987b906cd364">Cleanup_Delete</a>);</div><div class="line"></div><div class="line"><span class="comment">// Open the camera. Camera device removal is only detected while the camera is open.</span></div><div class="line">camera.Open();</div><div class="line"></div><div class="line"><span class="comment">// Now, try to detect that the camera has been removed:</span></div><div class="line"></div><div class="line"><span class="comment">// Ask the user to disconnect a device</span></div><div class="line">loopCount = c_loopCounterInitialValue;</div><div class="line">cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">&quot;Please disconnect the device (timeout &quot;</span> &lt;&lt; loopCount / 4 &lt;&lt; <span class="stringliteral">&quot;s) &quot;</span> &lt;&lt; endl;</div><div class="line"></div><div class="line"><span class="keywordflow">try</span></div><div class="line">{</div><div class="line">    <span class="comment">// Get a camera parameter using generic parameter access.</span></div><div class="line">    CIntegerParameter width(camera.GetNodeMap(), <span class="stringliteral">&quot;Width&quot;</span>);</div><div class="line"></div><div class="line">    <span class="comment">// The following loop accesses the camera. It could also be a loop that is</span></div><div class="line">    <span class="comment">// grabbing images. The device removal is handled in the exception handler.</span></div><div class="line">    <span class="keywordflow">while</span> ( loopCount &gt; 0)</div><div class="line">    {</div><div class="line">        <span class="comment">// Print a &quot;.&quot; every few seconds to tell the user we&#39;re waiting for the callback.</span></div><div class="line">        <span class="keywordflow">if</span> (--loopCount % 4 == 0)</div><div class="line">        {</div><div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;.&quot;</span>;</div><div class="line">            cout.flush();</div><div class="line">        }</div><div class="line">        WaitObject::Sleep(250);</div><div class="line"></div><div class="line">        <span class="comment">// Change the width value in the camera depending on the loop counter.</span></div><div class="line">        <span class="comment">// Any access to the camera like setting parameters or grabbing images</span></div><div class="line">        <span class="comment">// will fail throwing an exception if the camera has been disconnected.</span></div><div class="line">        width.SetValue( width.GetMax() - (width.GetInc() * (loopCount % 2)));</div><div class="line">    }</div><div class="line"></div><div class="line">}</div><div class="line"><span class="keywordflow">catch</span> (<span class="keyword">const</span> GenericException &amp;e)</div><div class="line">{</div><div class="line">    <span class="comment">// An exception occurred. Is it because the camera device has been physically removed?</span></div><div class="line"></div><div class="line">    <span class="comment">// Known issue: Wait until the system safely detects a possible removal.</span></div><div class="line">    WaitObject::Sleep(1000);</div><div class="line"></div><div class="line">    <span class="keywordflow">if</span> ( camera.IsCameraDeviceRemoved())</div><div class="line">    {</div><div class="line">        <span class="comment">// The camera device has been removed. This caused the exception.</span></div><div class="line">        cout &lt;&lt; endl;</div><div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;The camera has been removed from the computer.&quot;</span> &lt;&lt; endl;</div><div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;The camera device removal triggered an expected exception:&quot;</span> &lt;&lt; endl</div><div class="line">            &lt;&lt; e.GetDescription() &lt;&lt; endl;</div><div class="line">    }</div><div class="line">    <span class="keywordflow">else</span></div><div class="line">    {</div><div class="line">        <span class="comment">// An unexpected error has occurred.</span></div><div class="line">        <span class="comment">// In this example it is handled by exiting the program.</span></div><div class="line">        <span class="keywordflow">throw</span>;</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordflow">if</span> ( !camera.IsCameraDeviceRemoved())</div><div class="line">    cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">&quot;Timeout expired&quot;</span> &lt;&lt; endl;</div><div class="line"></div><div class="line"><span class="comment">// Destroy the Pylon Device representing the detached camera device.</span></div><div class="line"><span class="comment">// It can&#39;t be used anymore.</span></div><div class="line">camera.DestroyDevice();</div></div><!-- fragment --><p>The above code snippets can be found in the code of the <a class="el" href="sample_code.html#sample_DeviceRemovalHandling">DeviceRemovalHandling</a> sample.</p>
<dl class="section note"><dt>Note</dt><dd>The <code>OnCameraDeviceRemoved</code> call is made from a separate thread.</dd></dl>
<h1><a class="anchor" id="hi_parsingchunks_ref"></a>
Accessing Chunk Features</h1>
<p>Basler Cameras can send additional information appended to the image data, such as frame counters, time stamps, and CRC checksums. Data chunks are automatically parsed by the Instant Camera class if activated. The following example shows how to do this using the <a class="el" href="class_pylon_1_1_c_basler_universal_instant_camera.html"><code>CBaslerUniversalInstantCamera</code> </a> class.</p>
<div class="fragment"><div class="line"><span class="comment">// Enable chunks in general.</span></div><div class="line"><span class="keywordflow">if</span> (!camera.ChunkModeActive.TrySetValue(<span class="keyword">true</span>))</div><div class="line">{</div><div class="line">    <span class="keywordflow">throw</span> <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>( <span class="stringliteral">&quot;The camera doesn&#39;t support chunk features&quot;</span>);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Enable time stamp chunks.</span></div><div class="line">camera.ChunkSelector.SetValue(ChunkSelector_Timestamp);</div><div class="line">camera.ChunkEnable.SetValue(<span class="keyword">true</span>);</div><div class="line"></div><div class="line"><span class="comment">// Enable frame counter chunks?</span></div><div class="line"><span class="keywordflow">if</span> (camera.ChunkSelector.TrySetValue(ChunkSelector_Framecounter)) </div><div class="line">{</div><div class="line">    <span class="comment">// USB camera devices provide generic counters.</span></div><div class="line">    <span class="comment">// An explicit FrameCounter value is not provided by USB camera devices.</span></div><div class="line">    <span class="comment">// Enable frame counter chunks.</span></div><div class="line">    camera.ChunkEnable.SetValue(<span class="keyword">true</span>);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Enable CRC checksum chunks.</span></div><div class="line">camera.ChunkSelector.SetValue(ChunkSelector_PayloadCRC16);</div><div class="line">camera.ChunkEnable.SetValue(<span class="keyword">true</span>);</div></div><!-- fragment --><p>The chunk data can be accessed via parameter members of the <a class="el" href="class_pylon_1_1_c_basler_universal_grab_result_ptr.html"><code>CBaslerUniversalGrabResultPtr</code> </a> data class or using the provided chunk data node map (not shown).</p>
<div class="fragment"><div class="line">        <span class="comment">// Camera.StopGrabbing() is called automatically by the RetrieveResult() method</span></div><div class="line">        <span class="comment">// when c_countOfImagesToGrab images have been retrieved.</span></div><div class="line">        <span class="keywordflow">while</span>( camera.IsGrabbing())</div><div class="line">        {</div><div class="line">            <span class="comment">// Wait for an image and then retrieve it. A timeout of 5000 ms is used.</span></div><div class="line">            <span class="comment">// RetrieveResult calls the image event handler&#39;s OnImageGrabbed method.</span></div><div class="line">            camera.RetrieveResult( 5000, ptrGrabResult, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga038e4dd8fbd49dd4e7ec17cc605d1344af73671a5f5093f8159a973c0ef016a78">TimeoutHandling_ThrowException</a>);</div><div class="line"></div><div class="line"><span class="preprocessor">#ifdef PYLON_WIN_BUILD</span></div><div class="line">            <span class="comment">// Display the image</span></div><div class="line">            Pylon::DisplayImage(1, ptrGrabResult);</div><div class="line"><span class="preprocessor">#endif</span></div><div class="line"></div><div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;GrabSucceeded: &quot;</span> &lt;&lt; ptrGrabResult-&gt;GrabSucceeded() &lt;&lt; endl;</div><div class="line"></div><div class="line">            <span class="comment">// The result data is automatically filled with received chunk data.</span></div><div class="line">            <span class="comment">// (Note:  This is not the case when using the low-level API)</span></div><div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;SizeX: &quot;</span> &lt;&lt; ptrGrabResult-&gt;GetWidth() &lt;&lt; endl;</div><div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;SizeY: &quot;</span> &lt;&lt; ptrGrabResult-&gt;GetHeight() &lt;&lt; endl;</div><div class="line">            <span class="keyword">const</span> uint8_t *pImageBuffer = (uint8_t *) ptrGrabResult-&gt;GetBuffer();</div><div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;Gray value of first pixel: &quot;</span> &lt;&lt; (uint32_t) pImageBuffer[0] &lt;&lt; endl;</div><div class="line"></div><div class="line">            <span class="comment">// Check to see if a buffer containing chunk data has been received.</span></div><div class="line">            <span class="keywordflow">if</span> (<a class="code" href="group___pylon___instant_camera_api_generic.html#ggaf50b993da3a56a8a843e4d54e15b2329a5424a047d0e7ac6d548ced0dcad05b3e">PayloadType_ChunkData</a> != ptrGrabResult-&gt;GetPayloadType())</div><div class="line">            {</div><div class="line">                <span class="keywordflow">throw</span> <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>( <span class="stringliteral">&quot;Unexpected payload type received.&quot;</span>);</div><div class="line">            }</div><div class="line"></div><div class="line">            <span class="comment">// Since we have activated the CRC Checksum feature, we can check</span></div><div class="line">            <span class="comment">// the integrity of the buffer first.</span></div><div class="line">            <span class="comment">// Note: Enabling the CRC Checksum feature is not a prerequisite for using</span></div><div class="line">            <span class="comment">// chunks. Chunks can also be handled when the CRC Checksum feature is deactivated.</span></div><div class="line">            <span class="keywordflow">if</span> (ptrGrabResult-&gt;HasCRC() &amp;&amp; ptrGrabResult-&gt;CheckCRC() == <span class="keyword">false</span>)</div><div class="line">            {</div><div class="line">                <span class="keywordflow">throw</span> <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>( <span class="stringliteral">&quot;Image was damaged!&quot;</span>);</div><div class="line">            }</div><div class="line"></div><div class="line">            <span class="comment">// Access the chunk data attached to the result.</span></div><div class="line">            <span class="comment">// Before accessing the chunk data, you should check to see</span></div><div class="line">            <span class="comment">// if the chunk is readable. When it is readable, the buffer</span></div><div class="line">            <span class="comment">// contains the requested chunk data.</span></div><div class="line">            <span class="keywordflow">if</span> (ptrGrabResult-&gt;ChunkTimestamp.IsReadable())</div><div class="line">            {</div><div class="line">                cout &lt;&lt; <span class="stringliteral">&quot;TimeStamp (Result): &quot;</span> &lt;&lt; ptrGrabResult-&gt;ChunkTimestamp.GetValue() &lt;&lt; endl;</div><div class="line">            }</div><div class="line"></div><div class="line">            <span class="comment">// USB camera devices provide generic counters. An explicit FrameCounter value is not provided by USB camera devices.</span></div><div class="line">            <span class="keywordflow">if</span> (ptrGrabResult-&gt;ChunkFramecounter.IsReadable())</div><div class="line">            {</div><div class="line">                cout &lt;&lt; <span class="stringliteral">&quot;FrameCounter (Result): &quot;</span> &lt;&lt; ptrGrabResult-&gt;ChunkFramecounter.GetValue() &lt;&lt; endl;</div><div class="line">            }</div><div class="line">            </div><div class="line">            cout &lt;&lt; endl;</div><div class="line">        }</div></div><!-- fragment --><p>The above code snippets can be found in the code of the <a class="el" href="sample_code.html#sample_Grab_ChunkImage">Grab_ChunkImage</a> sample.</p>
<h1><a class="anchor" id="hi_grabbingevents_ref"></a>
Handling Camera Events</h1>
<p>Basler GigE Vision and USB3 Vision cameras can send event messages. For example, when a sensor exposure has finished, the camera can send an Exposure End event to the computer. The event can be received by the computer before the image data for the finished exposure has been completely transferred. This is e.g. useful for avoiding unnecessary delay by moving an imaged object further only before the related image data transfer is complete.</p>
<p>The event messages are automatically retrieved and processed by the InstantCamera classes. The information carried by event messages is exposed as nodes in the camera node map and can be accessed like "normal" camera parameters. These nodes are updated when a camera event is received. You can register camera event handler objects that are triggered when event data has been received.</p>
<p>The following camera event handler is used in the camera event example below, which prints the event data on the screen.</p>
<div class="fragment"><div class="line"><span class="comment">// Example handler for camera events.</span></div><div class="line"><span class="keyword">class </span>CSampleCameraEventHandler : <span class="keyword">public</span> CBaslerUniversalCameraEventHandler</div><div class="line">{</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="comment">// Only very short processing tasks should be performed by this method. Otherwise, the event notification will block the</span></div><div class="line">    <span class="comment">// processing of images.</span></div><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">void</span> OnCameraEvent( CBaslerUniversalInstantCamera&amp; camera, intptr_t userProvidedId, <a class="code" href="struct_gen_api_1_1_i_node.html">GenApi::INode</a>* <span class="comment">/* pNode */</span>)</div><div class="line">    {</div><div class="line">        std::cout &lt;&lt; std::endl;</div><div class="line">        <span class="keywordflow">switch</span> ( userProvidedId )</div><div class="line">        {</div><div class="line">        <span class="keywordflow">case</span> eMyExposureEndEvent: <span class="comment">// Exposure End event</span></div><div class="line">            <span class="keywordflow">if</span>(camera.EventExposureEndFrameID.IsReadable()) <span class="comment">// Applies to cameras based on SFNC 2.0 or later, e.g, USB cameras</span></div><div class="line">            {</div><div class="line">                cout &lt;&lt; <span class="stringliteral">&quot;Exposure End event. FrameID: &quot;</span> &lt;&lt; camera.EventExposureEndFrameID.GetValue() &lt;&lt; <span class="stringliteral">&quot; Timestamp: &quot;</span> &lt;&lt; camera.EventExposureEndTimestamp.GetValue() &lt;&lt; std::endl &lt;&lt; std::endl;</div><div class="line">            }</div><div class="line">            <span class="keywordflow">else</span></div><div class="line">            {</div><div class="line">                cout &lt;&lt; <span class="stringliteral">&quot;Exposure End event. FrameID: &quot;</span> &lt;&lt; camera.ExposureEndEventFrameID.GetValue() &lt;&lt; <span class="stringliteral">&quot; Timestamp: &quot;</span> &lt;&lt; camera.ExposureEndEventTimestamp.GetValue() &lt;&lt; std::endl &lt;&lt; std::endl;</div><div class="line">            }</div><div class="line">            <span class="keywordflow">break</span>;</div><div class="line">        <span class="keywordflow">case</span> eMyEventOverrunEvent:  <span class="comment">// Event Overrun event</span></div><div class="line">            cout &lt;&lt; <span class="stringliteral">&quot;Event Overrun event. FrameID: &quot;</span> &lt;&lt; camera.EventOverrunEventFrameID.GetValue() &lt;&lt; <span class="stringliteral">&quot; Timestamp: &quot;</span> &lt;&lt; camera.EventOverrunEventTimestamp.GetValue() &lt;&lt; std::endl &lt;&lt; std::endl;</div><div class="line">            <span class="keywordflow">break</span>;</div><div class="line">        }</div><div class="line">    }</div><div class="line">};</div></div><!-- fragment --><p>Handling camera events is disabled by default and needs to be activated first:</p>
<div class="fragment"><div class="line"><span class="comment">// Camera event processing must be activated first, the default is off.</span></div><div class="line">camera.GrabCameraEvents = <span class="keyword">true</span>;</div></div><!-- fragment --><p>To register a camera event handler the name of the event data node updated on a camera event and a user provided ID need to be passed. The user provided ID can be used to distinguish different events handled by the same event handler.</p>
<div class="fragment"><div class="line"><span class="comment">//Enumeration used for distinguishing different events.</span></div><div class="line"><span class="keyword">enum</span> MyEvents</div><div class="line">{</div><div class="line">    eMyExposureEndEvent  = 100,</div><div class="line">    eMyEventOverrunEvent = 200</div><div class="line">    <span class="comment">// More events can be added here.    </span></div><div class="line">};</div><div class="line"></div><div class="line">...</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// Cameras based on SFNC 2.0 or later, e.g., USB cameras</span></div><div class="line">if (camera.GetSfncVersion() &gt;= Sfnc_2_0_0) </div><div class="line">{</div><div class="line">    <span class="comment">// Register an event handler for the Exposure End event. For each event type, there is a &quot;data&quot; node</span></div><div class="line">    <span class="comment">// representing the event. The actual data that is carried by the event is held by child nodes of the</span></div><div class="line">    <span class="comment">// data node. In the case of the Exposure End event, the child nodes are EventExposureEndFrameID and EventExposureEndTimestamp.</span></div><div class="line">    <span class="comment">// The CSampleCameraEventHandler demonstrates how to access the child nodes within</span></div><div class="line">    <span class="comment">// a callback that is fired for the parent data node.</span></div><div class="line">    <span class="comment">// The user-provided ID eMyExposureEndEvent can be used to distinguish between multiple events (not shown).</span></div><div class="line">    camera.RegisterCameraEventHandler(pHandler1, <span class="stringliteral">&quot;EventExposureEndData&quot;</span>, eMyExposureEndEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda622d43aab16f129b874526cd63d1a74b">RegistrationMode_ReplaceAll</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div><div class="line">    <span class="comment">// The handler is registered for both, the EventExposureEndFrameID and the EventExposureEndTimestamp</span></div><div class="line">    <span class="comment">// node. These nodes represent the data carried by the Exposure End event.</span></div><div class="line">    <span class="comment">// For each Exposure End event received, the handler will be called twice, once for the frame ID, and</span></div><div class="line">    <span class="comment">// once for the time stamp.</span></div><div class="line">    camera.RegisterCameraEventHandler(pHandler2, <span class="stringliteral">&quot;EventExposureEndFrameID&quot;</span>, eMyExposureEndEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div><div class="line">    camera.RegisterCameraEventHandler(pHandler2, <span class="stringliteral">&quot;EventExposureEndTimestamp&quot;</span>, eMyExposureEndEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div><div class="line">}</div><div class="line"><span class="keywordflow">else</span> </div><div class="line">{</div><div class="line">    <span class="comment">// Register an event handler for the Exposure End event. For each event type, there is a &quot;data&quot; node</span></div><div class="line">    <span class="comment">// representing the event. The actual data that is carried by the event is held by child nodes of the</span></div><div class="line">    <span class="comment">// data node. In the case of the Exposure End event, the child nodes are ExposureEndEventFrameID, ExposureEndEventTimestamp,</span></div><div class="line">    <span class="comment">// and ExposureEndEventStreamChannelIndex. The CSampleCameraEventHandler demonstrates how to access the child nodes within</span></div><div class="line">    <span class="comment">// a callback that is fired for the parent data node.</span></div><div class="line">    camera.RegisterCameraEventHandler(pHandler1, <span class="stringliteral">&quot;ExposureEndEventData&quot;</span>, eMyExposureEndEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda622d43aab16f129b874526cd63d1a74b">RegistrationMode_ReplaceAll</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div><div class="line"></div><div class="line">    <span class="comment">// Register the same handler for a second event. The user-provided ID can be used</span></div><div class="line">    <span class="comment">// to distinguish between the events.</span></div><div class="line">    camera.RegisterCameraEventHandler(pHandler1, <span class="stringliteral">&quot;EventOverrunEventData&quot;</span>, eMyEventOverrunEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div><div class="line"></div><div class="line">    <span class="comment">// The handler is registered for both, the ExposureEndEventFrameID and the ExposureEndEventTimestamp</span></div><div class="line">    <span class="comment">// node. These nodes represent the data carried by the Exposure End event.</span></div><div class="line">    <span class="comment">// For each Exposure End event received, the handler will be called twice, once for the frame ID, and</span></div><div class="line">    <span class="comment">// once for the time stamp.</span></div><div class="line">    camera.RegisterCameraEventHandler(pHandler2, <span class="stringliteral">&quot;ExposureEndEventFrameID&quot;</span>, eMyExposureEndEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div><div class="line">    camera.RegisterCameraEventHandler(pHandler2, <span class="stringliteral">&quot;ExposureEndEventTimestamp&quot;</span>, eMyExposureEndEvent, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga6ad39f74e5f882a64461ad02c70567eda06f0a0d28b2552f5b7240e2344d37302">RegistrationMode_Append</a>, <a class="code" href="group___pylon___instant_camera_api_generic.html#ggae495d43181dadd7d44dc47ae1542fed5ab2a4bc04535c971546bf9ad9511e80dc">Cleanup_None</a>);</div><div class="line">}</div></div><!-- fragment --><p>The event of interest must be enabled in the camera. Events are then handled in the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3af3b05b85ea0aeb68eb5fb1b6dba0c8"><code>RetrieveResult()</code> </a> call while waiting for images.</p>
<div class="fragment"><div class="line"><span class="comment">// Enable sending of Exposure End events.</span></div><div class="line"><span class="comment">// Select the event to receive.</span></div><div class="line">camera.EventSelector.SetValue(EventSelector_ExposureEnd);</div><div class="line"></div><div class="line"><span class="comment">// Enable it.</span></div><div class="line"><span class="keywordflow">if</span> (!camera.EventNotification.TrySetValue(EventNotification_On)) </div><div class="line">{</div><div class="line">    <span class="comment">// scout-f, scout-g, and aviator GigE cameras use a different value</span></div><div class="line">    camera.EventNotification.SetValue(EventNotification_GenICamEvent);</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// Enable event notification for the EventOverrun event, if available</span></div><div class="line"><span class="keywordflow">if</span> (camera.EventSelector.TrySetValue(EventSelector_EventOverrun))</div><div class="line">{</div><div class="line">    <span class="comment">// Enable it.</span></div><div class="line">    <span class="keywordflow">if</span> (!camera.EventNotification.TrySetValue(EventNotification_On)) </div><div class="line">    {</div><div class="line">        <span class="comment">// scout-f, scout-g, and aviator GigE cameras use a different value</span></div><div class="line">        camera.EventNotification.SetValue(EventNotification_GenICamEvent);</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// Start the grabbing of c_countOfImagesToGrab images.</span></div><div class="line">camera.StartGrabbing( c_countOfImagesToGrab);</div><div class="line"></div><div class="line"><span class="comment">// This smart pointer will receive the grab result data.</span></div><div class="line">CGrabResultPtr ptrGrabResult;</div><div class="line"></div><div class="line"><span class="comment">// Camera.StopGrabbing() is called automatically by the RetrieveResult() method</span></div><div class="line"><span class="comment">// when c_countOfImagesToGrab images have been retrieved.</span></div><div class="line"><span class="keywordflow">while</span> ( camera.IsGrabbing())</div><div class="line">{</div><div class="line">    <span class="comment">// Execute the software trigger. Wait up to 1000 ms for the camera to be ready for trigger.</span></div><div class="line">    <span class="keywordflow">if</span> ( camera.WaitForFrameTriggerReady( 1000, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga038e4dd8fbd49dd4e7ec17cc605d1344af73671a5f5093f8159a973c0ef016a78">TimeoutHandling_ThrowException</a>))</div><div class="line">    {</div><div class="line">        camera.ExecuteSoftwareTrigger();</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Retrieve grab results and notify the camera event and image event handlers.</span></div><div class="line">    camera.RetrieveResult( 5000, ptrGrabResult, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga038e4dd8fbd49dd4e7ec17cc605d1344af73671a5f5093f8159a973c0ef016a78">TimeoutHandling_ThrowException</a>);</div><div class="line">    <span class="comment">// Nothing to do here with the grab result, the grab results are handled by the registered event handler.</span></div><div class="line">}</div></div><!-- fragment --><p>The above code snippets can be found in the code of the <a class="el" href="sample_code.html#sample_Grab_CameraEvents">Grab_CameraEvents</a> sample.</p>
<h1><a class="anchor" id="GettingInformedAboutParameterChanges"></a>
Getting Informed About Parameter Changes</h1>
<p>The GenICam API provides the functionality for installing callback functions that will be called when a parameter's value or state (e.g. the access mode or value range) have been changed. It is possible to either install a C function or a C++ class member function as a callback.</p>
<p>Each callback is installed for a specific parameter. If the parameter itself has been touched or if another parameter that can influence the state of the parameter has been changed, the callback will be fired.</p>
<p>The following example demonstrates how to install callbacks for the <code>Width</code> parameter: </p><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;pylon/gige/BaslerGigEInstantcamera.h&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;ostream&gt;</span></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespace_pylon.html">Pylon</a>;</div><div class="line"><span class="keyword">using namespace </span>std;</div><div class="line"></div><div class="line"><span class="comment">// C callback function</span></div><div class="line"><span class="keywordtype">void</span> staticcallback(<a class="code" href="struct_gen_api_1_1_i_node.html">GenApi::INode</a>* pNode )</div><div class="line">{</div><div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;Perhaps the value or state of &quot;</span> &lt;&lt; pNode-&gt;<a class="code" href="struct_gen_api_1_1_i_node.html#a4840e3c5b4800d8ca5d629e73c96d204">GetName</a>() &lt;&lt; <span class="stringliteral">&quot;has changed.&quot;</span> &lt;&lt; endl;</div><div class="line">  <span class="keywordflow">if</span> ( <a class="code" href="group___gen_api___public_interface.html#ga9429c4373073d861a7daa9309b578dd7">GenApi::IsReadable</a>( pNode ) ) {</div><div class="line">    <a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CValuePtr</a> ptrValue( pNode );</div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;The current value is &quot;</span> &lt;&lt; ptrValue-&gt;ToString() &lt;&lt; endl;</div><div class="line">  }</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keyword">class </span>C</div><div class="line">{</div><div class="line"><span class="keyword">public</span>:</div><div class="line">  <span class="comment">// Member function as callback function</span></div><div class="line">  <span class="keywordtype">void</span> membercallback(<a class="code" href="struct_gen_api_1_1_i_node.html">GenApi::INode</a>* pNode )</div><div class="line">  {</div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Perhaps the value or state of &quot;</span> &lt;&lt; pNode-&gt;<a class="code" href="struct_gen_api_1_1_i_node.html#a4840e3c5b4800d8ca5d629e73c96d204">GetName</a>() &lt;&lt; <span class="stringliteral">&quot;has changed.&quot;</span> &lt;&lt; endl;</div><div class="line">    <span class="keywordflow">if</span> ( <a class="code" href="group___gen_api___public_interface.html#ga9429c4373073d861a7daa9309b578dd7">GenApi::IsReadable</a>( pNode ) ) {</div><div class="line">      <a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CValuePtr</a> ptrValue( pNode );</div><div class="line">      cout &lt;&lt; <span class="stringliteral">&quot;The current value is &quot;</span> &lt;&lt; ptrValue-&gt;ToString() &lt;&lt; endl;</div><div class="line">    }</div><div class="line">  }</div><div class="line">};</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main()</div><div class="line">{</div><div class="line">  <a class="code" href="class_pylon_1_1_pylon_auto_init_term.html">PylonAutoInitTerm</a> autoInitTerm;</div><div class="line"></div><div class="line">  C cb;  <span class="comment">// c.membercallback() will be installed as callback</span></div><div class="line"></div><div class="line">  <span class="comment">// Only look for cameras supported by Camera_t.</span></div><div class="line">  <a class="code" href="class_pylon_1_1_c_device_info.html">CDeviceInfo</a> info;</div><div class="line">  info.<a class="code" href="class_pylon_1_1_c_device_info.html#a9212c5956d9d7a8c205d0de022e3c633">SetDeviceClass</a>( Camera_t::DeviceClass());</div><div class="line"></div><div class="line">  <span class="comment">// Create an instant camera object with the first found camera device matching the specified device class.</span></div><div class="line">  CBaslerGigEInstantCamera_t Camera( <a class="code" href="class_pylon_1_1_c_tl_factory.html#a1d3fbd0bb73b4acd88de7cff893554ab">CTlFactory::GetInstance</a>().CreateFirstDevice( info));</div><div class="line">  Camera.Open();</div><div class="line"></div><div class="line">  <span class="comment">// Install the C-function as callback</span></div><div class="line">  <a class="code" href="namespace_gen_api.html#aa699284b069f02e89d85a0f7525a8777">GenApi::CallbackHandleType</a> h1 =</div><div class="line">    <a class="code" href="group___gen_api___public_utilities.html#ga9a5c3e2bce3cdc6db812068660832f1f">GenApi::Register</a>( Camera.Width.GetNode(), &amp;staticcallback );</div><div class="line"></div><div class="line">  <span class="comment">// Install a member function as callback</span></div><div class="line">  <a class="code" href="namespace_gen_api.html#aa699284b069f02e89d85a0f7525a8777">GenApi::CallbackHandleType</a> h2 =</div><div class="line">    <a class="code" href="group___gen_api___public_utilities.html#ga9a5c3e2bce3cdc6db812068660832f1f">GenApi::Register</a>( Camera.Width.GetNode(), cb, &amp;C::membercallback );</div><div class="line"></div><div class="line">  <span class="comment">// This will trigger the callback functions</span></div><div class="line">  Camera.Width.SetValue( 128 );</div><div class="line"></div><div class="line">  <span class="comment">// Uninstall the callback functions</span></div><div class="line">  Camera.Width.GetNode()-&gt;DeregisterCallback(h2);</div><div class="line">  Camera.Width.GetNode()-&gt;DeregisterCallback(h1);</div><div class="line"></div><div class="line">  <span class="comment">// Close the camera object</span></div><div class="line">  Camera.Close();</div><div class="line"></div><div class="line">}</div></div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>For the nodes of the camera node map a Camera Event Handler can alternatively be used to get informed about parameter changes. This is because a GenApi node call back is registered internally for the node identified by the node's name when a Camera Event handler is registered. This callback triggers a call to the <code>CCameraEventHandler::OnCameraEvent()</code> method. Using a Camera Event Handler can be more convenient. See the <a class="el" href="sample_code.html#sample_Grab_CameraEvents">Grab_CameraEvents</a> sample for more information about how to register a Camera Event Handler.</dd></dl>
<h1><a class="anchor" id="buffer_factory"></a>
Instant Camera Class and User Provided Buffers</h1>
<p>A buffer factory can be attached to an Instant Camera object for using user provided buffers. The use of a buffer factory is optional and intended for advanced use cases only. The buffer factory class must be derived from <a class="el" href="struct_pylon_1_1_i_buffer_factory.html" title="Usable to create a custom buffer factory when needed. ">Pylon::IBufferFactory</a>. An instance of a buffer factory object can be attached to an instance the Instant Camera class by calling <a class="el" href="class_pylon_1_1_c_instant_camera.html#a241b201d21860f4f8ba11cda277af957"><code>SetBufferFactory()</code> </a> . Buffers are allocated when StartGrabbing is called. A buffer factory must not be deleted while it is attached to the camera object and it must not be deleted until the last buffer is freed. To free all buffers the grab needs to be stopped and all grab results must be released or destroyed. The <a class="el" href="sample_code.html#sample_Grab_UsingBufferFactory">Grab_UsingBufferFactory</a> code sample illustrates the use of a buffer factory.</p>
<h1><a class="anchor" id="MulticastGrabbing"></a>
GigE Multicast/Broadcast: Grab Images of One Camera on Multiple Computers</h1>
<p>Basler GigE cameras can be configured to send the image data stream to multiple destinations. Either IP multicasts or IP broadcasts can be used.</p>
<h2><a class="anchor" id="TypeOfApplication"></a>
The Controlling Application and the Monitoring Application</h2>
<p>When multiple applications on different computers expect to receive data streams from the same camera, one application is responsible for configuring the camera and for starting and stopping the data acquisition. This application is called the <b>controlling application</b>. Other applications that also expect to receive the data stream are called <b>monitoring applications</b>. These applications must connect to the camera in read-only mode, and can read all camera parameters but can't change them.</p>
<p>Device enumeration and device creation is identical for the controlling and the monitoring application. Each application type must create a Camera Object for the camera device from which it will recieve data. The multicast device creation is realized in the same way as for unicast setups (see earlier explanation).</p>
<p>Example of the configuration of an Instant Camera to act as monitor:</p>
<div class="fragment"><div class="line">Camera.MonitorModeActive = <span class="keyword">true</span>;</div></div><!-- fragment --><p>When using the Low Level API, the parameters passed to the Camera Object's <code>Pylon::CBaslerGigECamera::Open()</code> method determine whether an application acts as controlling or as monitoring application. The following code snippet illustrates how a monitoring application must call the <code>Pylon::CBaslerGigECamera::Open()</code> method:</p>
<div class="fragment"><div class="line"><span class="comment">// Low Level-API only</span></div><div class="line"><span class="comment">// Open the camera in stream mode to receive multicast packets (monitoring mode)</span></div><div class="line"><span class="comment">// In this mode the camera must be controlled by another application that must be in controlling mode</span></div><div class="line">Camera.Open(<a class="code" href="group___pylon___transport_layer.html#gga8ef525f5ebe32f59483928d77bf96afcadd694606dc3643e5ef2b0cce271d1675">Stream</a>);</div></div><!-- fragment --><p>When using the low level API the controlling application can either call the <code>Pylon::CBaslerGigECamera::Open()</code> method without passing in any arguments (the default parameters for the <code>Pylon::CBaslerGigECamera::Open()</code> method make sure that the device will be opened in control and stream mode), or can specify the access mode for the <code>Pylon::CBaslerGigECamera::Open()</code> method explicitly:</p>
<div class="fragment"><div class="line"><span class="comment">// Open the camera in controlling mode but without setting the Exclusive flag for the access mode</span></div><div class="line">Camera.Open(<a class="code" href="group___pylon___transport_layer.html#gga8ef525f5ebe32f59483928d77bf96afcadd694606dc3643e5ef2b0cce271d1675">Stream</a> | <a class="code" href="group___pylon___transport_layer.html#gga8ef525f5ebe32f59483928d77bf96afca55c0ae5b52a7cbb9224ebb9f0ca347cb">Control</a>);</div></div><!-- fragment --><p>It is important that the controlling application does not set the <a class="el" href="group___pylon___transport_layer.html#ga8ef525f5ebe32f59483928d77bf96afc">Exclusive </a> flag for the access mode. Using the <code>Exclusive</code> flag would prevent monitoring applications from accessing the camera at all. When the controlling application also wants to receive camera events, the <code>Events</code> flag must be added to the access mode parameter.</p>
<p>The controlling application and the monitoring application must create stream grabber objects in the same way as is done in unicast setups. Configuring the stream grabber for multicasts or broadcasts is explained in the next sections.</p>
<h2><a class="anchor" id="SettingUpControllingApplication"></a>
Setting Up the Controlling Application for Enabling Multicast and Broadcast</h2>
<p>The <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#a311fcc50991e71fc4ab67608ecf9fc35">TransmissionType </a> parameter of the GigE stream grabber class can be used to configure whether the camera sends the data stream to a single destination or to multiple destinations.</p>
<p>When the camera sends the image data using <b>limited broadcasts</b>, where the camera sends the data to the address 255.255.255.255, the data is sent to all devices in the local network. 'Limited' means, that the data is not sent to destinations behind a router, e.g., to computers in the internet. To enable limited broadcasts, the controlling application must set the <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#a311fcc50991e71fc4ab67608ecf9fc35">TransmissionType </a> parameter to <code>TransmissionType_LimitedBroadcast</code>. The camera sends the data to a specific port. See the <a class="el" href="pylon_advanced_topics.html#PortSelection">Selecting a Destination Port</a> section for setting up the destination port that receives the data from the camera.</p>
<p>When the camera sends the image data using <b>subnet directed broadcasts</b>, the camera sends the data to all devices that are in the same subnet as the camera. To enable subnet directed broadcasts, set the <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#a311fcc50991e71fc4ab67608ecf9fc35">TransmissionType </a> parameter to <code>TransmissionType_SubnetDirectedBroadcast</code>. See the <a class="el" href="pylon_advanced_topics.html#PortSelection">Selecting a Destination Port</a> section for information about setting up the destination port that receives the data from the camera.</p>
<p>The disadvantage of using broadcasts is that the camera sends the data to all recipients in a network, regardless of whether or not the devices need the data. The network traffic causes a certain CPU load and consumes network bandwidth even for the devices not needing the streaming data.</p>
<p>When the camera sends the image data using <b>multicasts</b>, the data is only sent to those devices that expect the data stream. A device claims its interest in receiving the data by joining a so-called <b>multicast group</b>. A multicast group is defined by an IP address taken from the multicast address range (224.0.0.0 to 239.255.255.255). A member of a specific multicast group only receives data destined for this group. Data for other groups is not received. Usually, network adapters and network switches are able to filter network packets efficiently on hardware level, preventing a CPU load due to the multicast network traffic for those devices in the network, that are not part of the multicast group.</p>
<p>When multicasting is enabled for pylon, pylon automatically takes care of joining and leaving the multicast groups defined by the destination IP address. Keep in mind that some addresses from the multicast address range are reserved for general purposes. The address range from 239.255.0.0 to 239.255.255.255 is assigned by RFC 2365 as a locally administered address space. Use adresses in this range if you are not sure.</p>
<p>To enable multicast streaming, the controlling application must set the <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#a311fcc50991e71fc4ab67608ecf9fc35">TransmissionType </a> parameter to <code>TransmissionType_Multicast</code> and set the <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#aa913862b14cb209e1891f1004a779683">DestinationAddr </a> parameter to a valid multicast IP address. In addition to the address, a port must be specified. See the <a class="el" href="pylon_advanced_topics.html#PortSelection">Selecting a Destination Port</a> section for setting up the destination port that receives the data from the camera.</p>
<p>Example using the <a class="el" href="class_pylon_1_1_c_basler_universal_instant_camera.html"><code>CBaslerUniversalInstantCamera</code> </a> class:</p>
<div class="fragment"><div class="line">Camera.GetStreamGrabberParams().DestinationAddr = <span class="stringliteral">&quot;239.0.0.1&quot;</span>;</div><div class="line">Camera.GetStreamGrabberParams().DestinationPort = 49154;</div></div><!-- fragment --><p>Example (Low Level):</p>
<div class="fragment"><div class="line">StreamGrabber.DestinationAddr = <span class="stringliteral">&quot;239.0.0.1&quot;</span>;</div><div class="line">StreamGrabber.DestinationPort = 49154;</div></div><!-- fragment --><p>On protocol level, multicasting involves a so-called IGMP message (IGMP = Internet Group Management Protocol). To benefit from multicasting, managed network switches should be used. These managed network switches support the IGMP protocol and only forward multicast packets if there is a device connected that has joined the corresponding multicast group. If the switch does not support the IGMP protocol, multicast is equivalent to broadcasting.</p>
<p>When multiple cameras are to multicast in the same network, each camera should stream to a different multicast group. Streaming to different multicast groups reduces the CPU load and saves network bandwidth if the network switches used support the IGMP protocol.</p>
<h2><a class="anchor" id="SettingUpMonitorApplication"></a>
Setting Up the Monitoring Application for Receiving Multicast and Broadcast Streams</h2>
<p>Two cases must be differentiated: </p><ul>
<li>The monitoring application opens the stream grabber after the controlling application has set up its stream grabber for broadcasts or multicasts. </li>
<li>The monitoring application opens the stream grabber before the controlling application opens its stream grabber.</li>
</ul>
<p>For the first case, setting up astream grabber for a monitoring application is quite easy. Since the controlling application has already configured the camera (i.e., the destination address and the destination port are set by the controlling application), these settings can be easily read from the camera. To let the monitoring application'sstream grabber read the settings from the camera, the monitoring application must set thestream grabber's <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#a311fcc50991e71fc4ab67608ecf9fc35">TransmissionType </a> parameter to <code>TransmissionType_UseCameraConfig</code> and then call thestream grabber's <code>Open()</code> method.</p>
<p>Example using the <a class="el" href="class_pylon_1_1_c_basler_universal_instant_camera.html"><code>CBaslerUniversalInstantCamera</code> </a> class:</p>
<div class="fragment"><div class="line"><span class="comment">// Select transmission type. If the camera is already controlled by another application</span></div><div class="line"><span class="comment">// and configured for multicast or broadcast, the active camera configuration can be used</span></div><div class="line"><span class="comment">// (IP Address and Port will be auto set).</span></div><div class="line">Camera.GetStreamGrabberParams().TransmissionType = <a class="code" href="___basler_universal_stream_params_8h.html#a009268c357abbf828247dbd920cdd8b7ac4bcf71d6bcf5601b222a9215dfc0919">TransmissionType_UseCameraConfig</a>;</div><div class="line"></div><div class="line"><span class="comment">// Start grabbing...</span></div></div><!-- fragment --><p>Example (low level):</p>
<div class="fragment"><div class="line"><span class="comment">// Select transmission type. If the camera is already controlled by another application</span></div><div class="line"><span class="comment">// and configured for multicast or broadcast, the active camera configuration can be used</span></div><div class="line"><span class="comment">// (IP Address and Port will be auto set).</span></div><div class="line">StreamGrabber.TransmissionType = <a class="code" href="___basler_universal_stream_params_8h.html#a009268c357abbf828247dbd920cdd8b7ac4bcf71d6bcf5601b222a9215dfc0919">TransmissionType_UseCameraConfig</a>;</div><div class="line"></div><div class="line"><span class="comment">// Open the stream grabber</span></div><div class="line">StreamGrabber.Open();</div></div><!-- fragment --><p>For the second case, where the monitoring application opens the stream grabber object before the controlling application opens its stream grabber, the <code>TransmissionType_UseCameraConfig</code> can't be used. Instead, the controlling application and all monitoring applications must use the same settings for the following IP destination related parameters:</p>
<ul>
<li><a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#a311fcc50991e71fc4ab67608ecf9fc35">TransmissionType </a> </li>
<li><a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#aa913862b14cb209e1891f1004a779683">DestinationAddr </a> </li>
<li><a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#acaf00ea5787e7ef0660821882947ff3d">DestinationPort </a></li>
</ul>
<p>Note that, when using broadcasts, the <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#aa913862b14cb209e1891f1004a779683">DestinationAddr </a> parameter is read-only. <a class="el" href="namespace_pylon.html" title="Contains definitions of pylon types. ">Pylon</a> will configure the camera for using the correct broadcast address.</p>
<p>When the controlling application and the monitoring application set the destination related parameters explicitly, it does not matter which application opens the stream grabber first.</p>
<h2><a class="anchor" id="PortSelection"></a>
Selecting a Destination Port</h2>
<p>The destination for the camera's data is specified by the destination IP address and the destination IP port. For multicasts, the monitoring and the controlling application must configure the stream grabbers for the same multicast IP address. Correspondingly, for broadcasts, the monitoring and the controlling application must use the same broadcast IP address that is automatically set by pylon.</p>
<p>In both cases, the controlling and the monitoring application must specify the same destination port. All applications must use a port that is not already in use on all of the computers receiving the data stream. The destination port is set by using the stream grabber's <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#acaf00ea5787e7ef0660821882947ff3d">DestinationPort </a> parameter.</p>
<p>When a monitoring application sets the <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#a311fcc50991e71fc4ab67608ecf9fc35">TransmissionType </a> parameter to <code>TransmissionType_UseCameraConfig</code>, it automatically uses the port that the controlling application has written to the corresponding camera register. In that case, the controlling application must use a port that is not used for all the computer where monitoring applications are running on. Basler advises against using this auto-selection mechanism for choosing a broadcast or multicast port.</p>
<p>where the controlling application is running on and that is not used for all computers where monitoring applications are running on.</p>
<p>When the <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#acaf00ea5787e7ef0660821882947ff3d">DestinationPort </a> parameter is set to 0, pylon automatically selects an unused port. This is very convenient for applications using only unicast streaming. In the case of multicast or broadcast, a parameter value of 0 can only be used by the controlling application and only if the monitoring application uses the <code>TransmissionType_UseCameraConfig</code> value for the <a class="el" href="class_basler___universal_stream_params_1_1_c_universal_stream_params___params__v6__1__0.html#a311fcc50991e71fc4ab67608ecf9fc35">TransmissionType </a> parameter. Because the port auomatically chosen by the controlling application may already be in use on computers where monitoring applications are running, we do not recommend to use this auto selection mechanism for the port for broadcast or multicast.</p>
<h2><a class="anchor" id="MulticastGrabbingSub"></a>
Receiving Image Data</h2>
<p>For broadcast or multicast setups grabbing images is realized in the same way as for unicast setups. Controlling and monitoring applications must allocate memory for grabbing, register the buffers at the stream grabber, enqueue the buffers and retrieve them back from the stream grabber. The only difference between monitoring application and controlling application is that only the controlling application starts and stops the image acquisition in the camera.</p>
<h2><a class="anchor" id="MulticastSample"></a>
Sample Program</h2>
<p>The pylon SDK contains a simple sample program called <a class="el" href="sample_code.html#sample_Grab_MultiCast">Grab_MultiCast</a>. This sample illustrates how to set up a controlling application and a monitoring application for multicast.</p>
<h1><a class="anchor" id="ActionCommand"></a>
GigE Action Commands</h1>
<p>The action command feature lets you trigger actions in multiple GigE devices (e.g. cameras) at roughly the same time or at a defined point in time (scheduled action command) by using a single broadcast protocol message (without extra cabling). Action commands are used in cameras in the same way as for example the digital input lines.</p>
<p>After setting up the camera parameters required for action commands the methods <a class="el" href="struct_pylon_1_1_i_gig_e_transport_layer.html#afe8642580afe61f26401b69df54c1d61" title="Issue a broadcast action command. ">Pylon::IGigETransportLayer::IssueActionCommand</a> or <a class="el" href="struct_pylon_1_1_i_gig_e_transport_layer.html#a8d93af604c4cf634287af514cdda7ca2" title="Issue a scheduled action command via broadcast. ">Pylon::IGigETransportLayer::IssueScheduledActionCommand</a> can be used to trigger action commands. This is shown in the sample <a class="el" href="sample_code.html#sample_Grab_UsingActionCommand">Grab_UsingActionCommand</a>. The <a class="el" href="class_pylon_1_1_c_action_trigger_configuration.html" title="Changes the configuration of the camera so that it is triggered by the first available action command...">Pylon::CActionTriggerConfiguration</a> is used setup the required camera parameters in the sample. The <code>CActionTriggerConfiguration</code> is provided as header file. This makes it possible to see what parameters of the camera are changed. The code can be copied and modified for creating own configuration classes.</p>
<p>Consult the the camera User's Manual for more detailed information on action commands.</p>
<h1><a class="anchor" id="loadsavecamerafeatures"></a>
Saving and Restoring Camera Features to/from Files</h1>
<p>This section describes how to write the current values to file for those camera features that are readable and writable. It is also demonstrated how to write the saved feature values back to the device. Saving and restoring the camera features is performed by using the <a class="el" href="class_pylon_1_1_c_feature_persistence.html" title="Utility class for saving and restoring camera features to and from a file or string. ">Pylon::CFeaturePersistence</a> class.</p>
<h2><a class="anchor" id="readfeatures"></a>
Writing the Camera Features to a File</h2>
<p>Use the static <a class="el" href="class_pylon_1_1_c_feature_persistence.html#aafc8caa4484e6a744954c5e9c633051c" title="Saves the node map to the file. ">Pylon::CFeaturePersistence::Save()</a> method to save the current camera feature values to a file.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_utility_includes_8h.html">pylon/PylonUtilityIncludes.h</a>&gt;</span></div><div class="line"></div><div class="line">  <span class="comment">// ...</span></div><div class="line"></div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">char</span> Filename[] = <span class="stringliteral">&quot;NodeMap.pfs&quot;</span>; <span class="comment">// Pylon Feature Stream</span></div><div class="line"></div><div class="line">  <span class="comment">// ...</span></div><div class="line"></div><div class="line">  <span class="comment">// Open the camera</span></div><div class="line">  Camera.Open();</div><div class="line"></div><div class="line">  <span class="comment">// Save the content of the camera&#39;s node map into the file</span></div><div class="line">  <span class="keywordflow">try</span></div><div class="line">  {</div><div class="line">    CFeaturePersistence::Save( Filename, &amp;Camera.GetNodeMap() );</div><div class="line">  }</div><div class="line">  <span class="keywordflow">catch</span> (<a class="code" href="class_pylon_1_1_generic_exception.html">Pylon::GenericException</a> &amp;e)</div><div class="line">  {</div><div class="line">    <span class="comment">// Error handling</span></div><div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;An exception occurred!&quot;</span> &lt;&lt; endl &lt;&lt; e.<a class="code" href="class_pylon_1_1_generic_exception.html#a2cc3d2b0b9e0d6ae2df614292fd7ab4c">GetDescription</a>() &lt;&lt; endl;</div><div class="line">  }</div></div><!-- fragment --><h2><a class="anchor" id="savefeatures"></a>
Writing the Feature Values Back to the Camera</h2>
<p>Use the static method <a class="el" href="class_pylon_1_1_c_feature_persistence.html#ab0113f519bdd95b672daaf249bf21974" title="Loads the features from the file to the node map. ">Pylon::CFeaturePersistence::Load()</a> to restore the camera values from a file.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_utility_includes_8h.html">pylon/PylonUtilityIncludes.h</a>&gt;</span></div><div class="line">  <span class="comment">// ...</span></div><div class="line">  <span class="keyword">const</span> <span class="keywordtype">char</span> Filename[] = <span class="stringliteral">&quot;NodeMap.pfs&quot;</span>;          <span class="comment">// Pylon Feature Stream</span></div><div class="line"></div><div class="line">  <span class="comment">// ...</span></div><div class="line"></div><div class="line">  <span class="comment">// Open the camera</span></div><div class="line">  Camera.Open();</div><div class="line"></div><div class="line">  <span class="comment">// Read the content of the file back to the camera&#39;s node map with validation on</span></div><div class="line">  <span class="keywordflow">try</span></div><div class="line">  {</div><div class="line">    CFeaturePersistence::Load( Filename, &amp;Camera.GetNodeMap(), true );</div><div class="line">  }</div><div class="line">  <span class="keywordflow">catch</span> (<a class="code" href="class_pylon_1_1_generic_exception.html">Pylon::GenericException</a> &amp;e)</div><div class="line">  {</div><div class="line">    <span class="comment">// Error handling</span></div><div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;An exception occurred!&quot;</span> &lt;&lt; endl &lt;&lt; e.<a class="code" href="class_pylon_1_1_generic_exception.html#a2cc3d2b0b9e0d6ae2df614292fd7ab4c">GetDescription</a>() &lt;&lt; endl;</div><div class="line">  }</div></div><!-- fragment --><p>The code snippets in this section are taken from the <a class="el" href="sample_code.html#sample_ParametrizeCamera_LoadAndSave">ParametrizeCamera_LoadAndSave</a> sample.</p>
<h1><a class="anchor" id="shadingfileio"></a>
Transferring Shading Data to the Camera</h1>
<p>This section describes how to transfer gain shading data to the camera using the GenICam FileIO functionality.</p>
<p>Camera devices supporting the gain shading feature store the shading data as files in the camera's internal file system. These files are accessed using the GenICam <a class="el" href="_filestream_8h.html">Filestream </a> classes provided in the <a class="el" href="_filestream_8h.html" title="Definition of ODevFileStream and IDevFileStream. ">GenApi/Filestream.h</a> header file.</p>
<div class="fragment"><div class="line"><span class="comment">// Include files to use the PYLON API</span></div><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespace_pylon.html">Pylon</a>;</div><div class="line"></div><div class="line"><span class="comment">// for file upload</span></div><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_filestream_8h.html">GenApi/Filestream.h</a>&gt;</span></div><div class="line"></div><div class="line">  <span class="comment">// ...</span></div><div class="line"></div><div class="line">  <span class="comment">// Create the camera object of the first available camera</span></div><div class="line">  <span class="comment">// The camera object is used to set and get all available</span></div><div class="line">  <span class="comment">// camera features.</span></div><div class="line">  Camera_t Camera(pTl-&gt;<a class="code" href="struct_pylon_1_1_i_device_factory.html#a9891f54248fa6dc0f7cab171044458c4">CreateDevice</a>(devices[ 0 ]));</div><div class="line"></div><div class="line">  <span class="comment">// Open the camera</span></div><div class="line">  Camera.Open();</div><div class="line"></div><div class="line">  <span class="comment">// ...</span></div></div><!-- fragment --><p>GenICam defines two char based stream classes for easy to use read and write operations. </p><div class="fragment"><div class="line"><span class="keyword">typedef</span> ODevFileStreamBase&lt;char, std::char_traits&lt;char&gt; &gt; ODevFileStream;</div><div class="line"><span class="keyword">typedef</span> IDevFileStreamBase&lt;char, std::char_traits&lt;char&gt; &gt; IDevFileStream;</div></div><!-- fragment --><p>The <code>ODevFileStream</code> class is used for uploading data to the camera's file system. The <code>IDevFileStream</code> class is used for downloading data from the camera's file system.</p>
<p>Internally, the classes use the <a class="el" href="class_gen_api_1_1_file_protocol_adapter.html">GenApi::FileProtocolAdapter</a> class. The <a class="el" href="class_gen_api_1_1_file_protocol_adapter.html">GenApi::FileProtocolAdapter</a> class defines file based operations like open, close, read, and write.</p>
<p>One common parameter for these operations is the file name of the file to be used on the device file system. The file name must correspond to an existing file in the device file system. To retrieve a list of valid file names supported by the connected camera, read the entries of the "FileSelector" enumeration feature.</p>
<div class="fragment"><div class="line"><a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CEnumerationPtr</a> ptrFileSelector = Camera.GetNodeMap().GetNode(<span class="stringliteral">&quot;FileSelector&quot;</span>);</div><div class="line"><span class="keywordflow">if</span> ( ptrFileSelector.<a class="code" href="class_gen_api_1_1_c_pointer.html#a5ab02b4f880c9459473bf5db7d3c107f">IsValid</a>() ) {</div><div class="line">  <span class="keywordflow">try</span></div><div class="line">  {</div><div class="line">    <a class="code" href="class_gen_api_1_1node__vector.html">GenApi::NodeList_t</a> entries;</div><div class="line">    ptrFileSelector-&gt;GetEntries( entries );</div><div class="line">    <span class="keywordflow">for</span> ( GenApi::NodeList_t::iterator it = entries.begin(); it != entries.end(); ++it) {</div><div class="line">      <span class="keywordflow">if</span> (<a class="code" href="group___gen_api___public_interface.html#gaf50a08b3955f5d590b690fb25849b602">GenApi::IsAvailable</a>(*it)) {</div><div class="line">        <a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CEnumEntryPtr</a> pEntry = (*it);</div><div class="line">        <span class="keywordflow">if</span> ( NULL != pEntry ) {</div><div class="line">          <a class="code" href="struct_gen_api_1_1_i_node.html">GenApi::INode</a>* pNode = pEntry-&gt;GetNode();</div><div class="line">          <a class="code" href="class_gen_i_cam_1_1gcstring.html">GenICam::gcstring</a> strFilename = pEntry-&gt;GetSymbolic().c_str();</div><div class="line"></div><div class="line">          <span class="comment">// Do with strFilename whatever you want (e.g. adding to a list)</span></div><div class="line">          <span class="comment">// ...</span></div><div class="line"></div><div class="line">        } <span class="comment">// if</span></div><div class="line">      } <span class="comment">// if</span></div><div class="line">    } <span class="comment">// for</span></div><div class="line">  }</div><div class="line">  <span class="keywordflow">catch</span> (<a class="code" href="class_pylon_1_1_generic_exception.html">Pylon::GenericException</a> &amp;e)</div><div class="line">  {</div><div class="line">    <span class="comment">// Handle error</span></div><div class="line">    <span class="comment">// ...</span></div><div class="line">  }</div><div class="line">} <span class="comment">// if</span></div></div><!-- fragment --><h2><a class="anchor" id="uploadShadingData"></a>
Upload Shading Data to the Camera</h2>
<p>The camera device stores gain shading data in files named "UserGainShading1", "UserGainShading2", etc.</p>
<p>To upload gain shading data to the camera use the <code>ODevFileStream</code> class.</p>
<div class="fragment"><div class="line"><span class="comment">// Name of the file in the camera where shading data is stored</span></div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">char</span> CameraFilename[] = <span class="stringliteral">&quot;UserGainShading1&quot;</span>;</div><div class="line"></div><div class="line"><span class="comment">// ...</span></div><div class="line"></div><div class="line"><span class="comment">// Read data from local file into pBuf</span></div><div class="line"><span class="keywordtype">char</span> *pBuf = <span class="keyword">new</span> <span class="keywordtype">char</span>[Size];</div><div class="line"><span class="keywordtype">size_t</span> read = fread(pBuf, 1, Size, fp);</div><div class="line">fclose(fp);</div><div class="line"></div><div class="line"><span class="keywordflow">if</span> (read != Size) {</div><div class="line">    <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>(<span class="stringliteral">&quot;Failed to read from file &#39;%s&#39;\n&quot;</span>, pLocalFilename);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Transfer data to camera</span></div><div class="line">ODevFileStream stream(&amp;Camera.GetNodeMap(), CameraFilename);</div><div class="line">stream.write(pBuf, streamsize(Size));</div><div class="line"><span class="keywordflow">if</span> (stream.fail()) {</div><div class="line">    <span class="comment">// Do some error handling</span></div><div class="line">    <span class="comment">// ...</span></div><div class="line">}</div><div class="line"></div><div class="line">stream.close();</div><div class="line"><span class="keyword">delete</span>[] pBuf;</div><div class="line"></div><div class="line"><span class="comment">// ...</span></div></div><!-- fragment --><p> This code snippet is taken from the <a class="el" href="sample_code.html#sample_ParametrizeCamera_Shading">ParametrizeCamera_Shading</a> sample program.</p>
<h2><a class="anchor" id="downloadShadingData"></a>
Download Shading Data From the Camera</h2>
<p>Downloading shading data from the camera to a buffer is as simple as uploading shading data.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#define FILEBUFFSIZE 1024   // size of receive buffer!</span></div><div class="line"><span class="comment">// Name of the file in the camera where shading data is stored</span></div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keywordtype">char</span> CameraFilename[] = <span class="stringliteral">&quot;UserGainShading1&quot;</span>;</div><div class="line"></div><div class="line"><span class="keywordtype">char</span> *pBuffer = <span class="keyword">new</span> <span class="keywordtype">char</span>[FILEBUFFSIZE];</div><div class="line"></div><div class="line"><span class="comment">// ...</span></div><div class="line"></div><div class="line"><span class="comment">// Transfer data from camera</span></div><div class="line">IDevFileStream stream(&amp;Camera.GetNodeMap(), CameraFilename);</div><div class="line"><span class="keywordflow">if</span> (stream.fail()) {</div><div class="line">  <a class="code" href="group___base___public_impl.html#ga16e6d812cf9af13e0f4106c77689e46b">RUNTIME_EXCEPTION</a>(<span class="stringliteral">&quot;Failed to open camerafile file &#39;%s&#39;\n&quot;</span>, CameraFilename);</div><div class="line">}</div><div class="line"><span class="keywordtype">int</span> nBytesRead = 0;</div><div class="line"><span class="keywordflow">if</span> (stream.is_open()) {</div><div class="line">  <span class="keywordflow">do</span> {</div><div class="line">    stream.read(pBuffer, FILEBUFFSIZE); <span class="comment">// read max. FILEBUFFSIZE number of bytes from camera</span></div><div class="line">    nBytesRead = stream.gcount();     <span class="comment">// get number of bytes read</span></div><div class="line">    <span class="keywordflow">if</span> (nBytesRead &gt; 0) {</div><div class="line">      <span class="comment">// Do something with the received bytes in pBuffer e.g. writing to disk</span></div><div class="line">      <span class="comment">// file.write(pBuffer, nBytesRead);</span></div><div class="line">      <span class="comment">// ...</span></div><div class="line">    }</div><div class="line">  } <span class="keywordflow">while</span> (nBytesRead == FILEBUFFSIZE);   <span class="comment">// if nBytesRead == FILEBUFFSIZE maybe there are more data to receive</span></div><div class="line">}</div><div class="line"></div><div class="line">stream.close();</div><div class="line"><span class="keyword">delete</span> [] pBuffer;</div></div><!-- fragment --><h1><a class="anchor" id="waitingformultiple"></a>
Waiting for Multiple Events</h1>
<h2><a class="anchor" id="WaitObjects"></a>
Wait Objects</h2>
<p>In applications, a separate thread is often dedicated to grabbing images. Typically, this grab thread must be synchronized with other threads of the application. For example, an application may want to signal the grab thread to terminate.</p>
<p>Wait Objects can be used to synchronize threads. The concept of Wait Objects allows you get information about events, e.g., grabbed images.</p>
<p>Wait Objects are an abstraction of operating system specific objects that can be either signaled or non-signaled. Wait Objects provide a wait operation that blocks until the Wait Object is signaled.</p>
<p>While the pylon interfaces return objects of the <a class="el" href="class_pylon_1_1_wait_object.html" title="A platform independent wait object. ">Pylon::WaitObject</a> type, pylon provides the <a class="el" href="class_pylon_1_1_wait_object_ex.html" title="A wait object that the user may signal. ">Pylon::WaitObjectEx</a> class that is to be instantiated by user applications. Use the static factory method <a class="el" href="class_pylon_1_1_wait_object_ex.html#a2366cd73da386f70a5b012a8db4a44be">WaitObjectEx::Create() </a> to create these wait objects.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="_pylon_includes_8h.html">pylon/PylonIncludes.h</a>&gt;</span></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespace_pylon.html">Pylon</a>;</div><div class="line"></div><div class="line">  <span class="comment">// ...</span></div><div class="line"></div><div class="line">  <a class="code" href="class_pylon_1_1_wait_object_ex.html">WaitObjectEx</a> wo( <a class="code" href="class_pylon_1_1_wait_object_ex.html#a2366cd73da386f70a5b012a8db4a44be">WaitObjectEx::Create</a>() );</div></div><!-- fragment --><p>The <a class="el" href="class_pylon_1_1_wait_object_ex.html#a33aecdc76a3f2b28f644875781087210">WaitObjectEx::Signal() </a> method is used to signal a wait object. The <a class="el" href="class_pylon_1_1_wait_object_ex.html#abd623b0c249d5c9117304d8375fa4ebf">WaitObjectEx::Reset() </a> method can be used to put the Wait Object into the non-signaled state.</p>
<div class="fragment"><div class="line"><span class="comment">// Put w0 into the signaled state</span></div><div class="line">w0.Signal();</div><div class="line"></div><div class="line"><span class="comment">// Put w0 into the non-signaled state</span></div><div class="line">w0.Reset();</div></div><!-- fragment --><h2><a class="anchor" id="WaitContainer"></a>
Container for Wait Objects</h2>
<p>The <a class="el" href="class_pylon_1_1_wait_objects.html" title="A set of wait objects. ">Pylon::WaitObjects</a> class is a container for Wait Objects and provides two methods of waiting for Wait Objects stored in the container: </p><ul>
<li>The <a class="el" href="class_pylon_1_1_wait_objects.html#a5624256c6bc93ae86be10a29b258d592" title="Wait for any one object to get signaled. ">Pylon::WaitObjects::WaitForAny()</a> method returns when at least one object in the container is signaled. </li>
<li>The <a class="el" href="class_pylon_1_1_wait_objects.html#ab697b680f24fdfee57f595b43d609542" title="Wait for all objects to get signaled. ">Pylon::WaitObjects::WaitForAll()</a> method returns when all objects in the container are signaled.</li>
</ul>
<div class="fragment"><div class="line"><span class="comment">// Create a container and insert two wait objects</span></div><div class="line">WaitObjects waitObjects;</div><div class="line">waitObjects.Add(w0);</div><div class="line">waitObjects.Add(w1);</div><div class="line"></div><div class="line"><span class="comment">// Wait for three seconds until any of the wait objects get signaled</span></div><div class="line"><span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> index;</div><div class="line"><span class="keywordflow">if</span> ( waitObjects.WaitForAny( 3000, &amp;index) ) {</div><div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;WaitObject w&quot;</span> &lt;&lt; index &lt;&lt; <span class="stringliteral">&quot; has been signaled&quot;</span> &lt;&lt; endl;</div><div class="line">}</div><div class="line"><span class="keywordflow">else</span> {</div><div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;Timeout occurred when waiting for wait objects&quot;</span> &lt;&lt; endl;</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Wait for three seconds until all of the wait objects are signaled</span></div><div class="line"><span class="keywordflow">if</span> ( waitObjects.WaitForAll(3000) ) {</div><div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;All wait objects are signaled&quot;</span> &lt;&lt; endl;</div><div class="line">} <span class="keywordflow">else</span> {</div><div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;Timeout occurred when waiting for wait objects&quot;</span> &lt;&lt; endl;</div><div class="line">}</div></div><!-- fragment --><h2><a class="anchor" id="WaitExample"></a>
Example</h2>
<p>The following code snippets illustrate how a grab thread uses the <a class="el" href="class_pylon_1_1_wait_objects.html#a5624256c6bc93ae86be10a29b258d592">WaitForAny() </a> method to simultaneously wait for buffers and a termination request.</p>
<p>After preparing for grabbing, the application's main thread starts the grab thread and sleeps for 5 seconds. </p><div class="fragment"><div class="line">  <span class="comment">// Start the grab thread. The grab thread starts the image acquisition</span></div><div class="line">  <span class="comment">// and grabs images</span></div><div class="line">  cout &lt;&lt; <span class="stringliteral">&quot;Going to start the grab thread&quot;</span> &lt;&lt; endl;</div><div class="line">  StartThread();</div><div class="line"></div><div class="line">  <span class="comment">// Let the thread grab images for 5 seconds</span></div><div class="line"><span class="preprocessor">#if defined(PYLON_WIN_BUILD)</span></div><div class="line">  Sleep(5000);</div><div class="line"><span class="preprocessor">#elif defined(PYLON_UNIX_BUILD)</span></div><div class="line">  sleep(5);</div><div class="line"><span class="preprocessor">#else</span></div><div class="line"><span class="preprocessor">  #error unsupported platform</span></div><div class="line"><span class="preprocessor">#endif</span></div></div><!-- fragment --><p>The grab thread sets up a Wait Object container holding the StreamGrabber's Wait Object and a <a class="el" href="class_pylon_1_1_wait_object_ex.html" title="A wait object that the user may signal. ">Pylon::WaitObjectEx</a>. The latter is used by the main thread to request the termination of grabbing:</p>
<div class="fragment"><div class="line"><span class="comment">// Create and prepare the wait object container</span></div><div class="line">WaitObjects waitObjects;</div><div class="line"></div><div class="line">waitObjects.Add( Camera.GetGrabResultWaitObject() );  <span class="comment">// Getting informed about grab results</span></div><div class="line">waitObjects.Add( m_TerminationEvent ); <span class="comment">// Getting informed about termination request</span></div></div><!-- fragment --><p>Then the grab thread enters an infinite loop that starts waiting for any of the Wait Objects:</p>
<div class="fragment"><div class="line">CGrabResultPtr result;   <span class="comment">// Grab result</span></div><div class="line"><span class="keywordtype">bool</span> terminate = <span class="keyword">false</span>;</div><div class="line"><span class="keywordflow">while</span> ( ! terminate ) {</div><div class="line">  <span class="keywordflow">if</span> ( ! waitObjects.WaitForAny( INFINITE, &amp;index ) ) {</div><div class="line">    <span class="comment">// Timeout occurred, should never happen when using INFINITE</span></div><div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;Timeout occurred????&quot;</span> &lt;&lt; endl;</div><div class="line">    <span class="keywordflow">break</span>;</div><div class="line">  }</div></div><!-- fragment --><p>When the <a class="el" href="class_pylon_1_1_wait_objects.html#a5624256c6bc93ae86be10a29b258d592">WaitForAny() </a> method returns with true, the value of <code>index</code> is used to determine whether a buffer has been grabbed or a request to terminate grabbing is pending:</p>
<div class="fragment"><div class="line"><span class="keywordflow">switch</span> ( index )</div><div class="line">{</div><div class="line"><span class="keywordflow">case</span> 0:  <span class="comment">// A grabbed buffer is available</span></div><div class="line">  <span class="keywordflow">if</span> ( m_Camera.RetrieveResult( 0, result, <a class="code" href="group___pylon___instant_camera_api_generic.html#gga038e4dd8fbd49dd4e7ec17cc605d1344a957ab0224b24e6361ceea112c5148067">TimeoutHandling_Return</a> ) ) {</div><div class="line">    <span class="keywordflow">if</span> ( result-&gt;GrabSucceeded() ) {</div><div class="line">      cout &lt;&lt; <span class="stringliteral">&quot;Successfully grabbed image &quot;</span> &lt;&lt; ++nSucc &lt;&lt; endl;</div><div class="line">      <span class="keywordtype">unsigned</span> <span class="keywordtype">char</span>* pPixel = (<span class="keywordtype">unsigned</span> <span class="keywordtype">char</span>*) result-&gt;GetBuffer();</div><div class="line">      <span class="comment">// Process buffer .....</span></div><div class="line">    }</div><div class="line">  } <span class="keywordflow">else</span> {</div><div class="line">    cerr &lt;&lt; <span class="stringliteral">&quot;Failed to retrieve result&quot;</span> &lt;&lt; endl;</div><div class="line">    terminate = <span class="keyword">true</span>;</div><div class="line">  }</div><div class="line">  <span class="keywordflow">break</span>;</div><div class="line"></div><div class="line"><span class="keywordflow">case</span> 1:  <span class="comment">// Received a termination request</span></div><div class="line">  terminate = <span class="keyword">true</span>;</div><div class="line">  <span class="keywordflow">break</span>;</div><div class="line">} <span class="comment">// switch</span></div></div><!-- fragment --><p>The main thread signals the grab thread to terminate by calling the <code>WaitObjectEx's</code> <a class="el" href="class_pylon_1_1_wait_object_ex.html#a33aecdc76a3f2b28f644875781087210">Signal() </a> method:</p>
<div class="fragment"><div class="line"><span class="comment">// Signal the thread to terminate</span></div><div class="line">cout &lt;&lt; <span class="stringliteral">&quot;Going to issue termination request&quot;</span> &lt;&lt; endl;</div><div class="line">m_TerminationEvent.Signal();</div></div><!-- fragment --><p>Now the main thread can join with the grab thread.</p>
<h2><a class="anchor" id="InterruptibleWait"></a>
Interruptible Wait Operation</h2>
<p>It was demonstrated in the previous section how a <a class="el" href="class_pylon_1_1_wait_object_ex.html" title="A wait object that the user may signal. ">Pylon::WaitObjectEx</a> can be used to signal a thread to terminate.</p>
<p>As an alternative to using dedicated Wait Objects to get informed about external events, the <a class="el" href="class_pylon_1_1_wait_object.html#a68b6d84aed84e7dd53c09a4fb78da7fa">WaitObject::WaitEx() </a> method can be used for waiting. This wait operation can be interrupted. For the Windows version of pylon, <a class="el" href="class_pylon_1_1_wait_object.html#a68b6d84aed84e7dd53c09a4fb78da7fa">WaitEx() </a> can be interrupted by a queued APC or an I/O completion routine. The Linux and macOS version of pylon, <a class="el" href="class_pylon_1_1_wait_object.html#a68b6d84aed84e7dd53c09a4fb78da7fa">WaitEx() </a> can be interrupted by signals.</p>
<p>Example: </p><div class="fragment"><div class="line"><span class="keywordtype">bool</span> terminate = <span class="keyword">false</span>;  <span class="comment">// Will be set to true when a signal has been detected</span></div><div class="line"><span class="comment">// Grab images until we get a signal</span></div><div class="line"><span class="keywordflow">while</span> ( ! terminate ) {</div><div class="line">  <span class="comment">// Wait for the grabbed image with timeout of 10 seconds. We want to be interruptible by signals.</span></div><div class="line">  waitex_result_t waitResult = StreamGrabber.GetWaitObject().WaitEx(10000, <span class="keyword">true</span>);</div><div class="line">  <span class="keywordflow">switch</span> ( waitResult )</div><div class="line">  {</div><div class="line">  <span class="keywordflow">case</span> <a class="code" href="namespace_pylon.html#a538b1d4292c8bc01c03d70952d365249a79103e30dda39bbb8ce87086895b948f">waitex_timeout</a>:  <span class="comment">// Timeout occurred, no buffer available</span></div><div class="line">    {</div><div class="line">      cerr &lt;&lt; <span class="stringliteral">&quot;Failed to grab image: timeout&quot;</span> &lt;&lt; endl;</div><div class="line">      <span class="keywordflow">continue</span>;</div><div class="line">    }</div><div class="line"></div><div class="line">  <span class="keywordflow">case</span> <a class="code" href="namespace_pylon.html#a538b1d4292c8bc01c03d70952d365249a1149c570bcbc84378d19f7317968b7ef">waitex_signaled</a>:  <span class="comment">// Buffer is available in the driver&#39;s output queue</span></div><div class="line">    {</div><div class="line">      <span class="comment">// Get the grab result</span></div><div class="line">      GrabResult Result;</div><div class="line">      StreamGrabber.RetrieveResult(Result);</div><div class="line"></div><div class="line">      <span class="keywordflow">if</span> (<a class="code" href="group___pylon___low_level_api.html#gga4afc5255837dea09eb304a583f0c9231abaa28d8ce6fd0b48ada460db0817ff07">Grabbed</a> == Result.Status()) {</div><div class="line">        <span class="comment">// Grabbing was successful, process image</span></div><div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;.&quot;</span> &lt;&lt; flush;</div><div class="line">      } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code" href="group___pylon___low_level_api.html#gga4afc5255837dea09eb304a583f0c9231a828c1f21b5fa8cfdd2e93c766484c808">Failed</a> == Result.Status())</div><div class="line">      {</div><div class="line">        <span class="comment">// Error Handling</span></div><div class="line">        cerr &lt;&lt; <span class="stringliteral">&quot;Failed to acquire image!&quot;</span> &lt;&lt; endl;</div><div class="line">        cerr &lt;&lt; <span class="stringliteral">&quot;Error code : 0x&quot;</span> &lt;&lt; hex</div><div class="line">          &lt;&lt; Result.GetErrorCode() &lt;&lt; endl;</div><div class="line">        cerr &lt;&lt; <span class="stringliteral">&quot;Error description : &quot;</span></div><div class="line">          &lt;&lt; Result.GetErrorDescription() &lt;&lt; endl;</div><div class="line">      }</div><div class="line"></div><div class="line">      <span class="comment">// Reuse the buffer for grabbing the next image</span></div><div class="line">      StreamGrabber.QueueBuffer(Result.Handle(), NULL);</div><div class="line">      <span class="keywordflow">break</span>;</div><div class="line">    }</div><div class="line"></div><div class="line">  <span class="keywordflow">case</span> <a class="code" href="namespace_pylon.html#a538b1d4292c8bc01c03d70952d365249a810470fa9eb0178dc0df56acf80610ce">waitex_alerted</a>:  <span class="comment">// Wait operation has been interrupted by a signal</span></div><div class="line">    {</div><div class="line">      cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">&quot;Got signal. Terminating application&quot;</span> &lt;&lt; endl;</div><div class="line">      terminate = <span class="keyword">true</span>;</div><div class="line">      <span class="keywordflow">break</span>;</div><div class="line">    }</div><div class="line">  } <span class="comment">// switch</span></div><div class="line">} <span class="comment">// while</span></div></div><!-- fragment --><p>This code snippet has been taken from the WaitEx sample that comes with the pylon for Linux SDK.</p>
<p>Corresponding to the <a class="el" href="class_pylon_1_1_wait_object.html#a68b6d84aed84e7dd53c09a4fb78da7fa">WaitObject::WaitEx() </a> method, the <a class="el" href="class_pylon_1_1_wait_objects.html" title="A set of wait objects. ">Pylon::WaitObjects</a> class provides the interruptable <a class="el" href="class_pylon_1_1_wait_objects.html#adec54801c4f9263b4821109ca4f87139">WaitForAnyEx() </a> and <a class="el" href="class_pylon_1_1_wait_objects.html#ab428b0df6dcaae482c78ac6c2f551163">WaitForAllEx() </a> methods.</p>
<h1><a class="anchor" id="highperformanceapps"></a>
Application Settings for High Performance</h1>
<p>The following settings are recommended for applications that require image processing at a constant frame rate and with low jitter:</p>
<ul>
<li>The packet size should be adjusted to the highest value supported by your network adapter and network setup, e.g. to a packet size of 8092 bytes. </li>
<li>The grab loop thread should have its priority set to a value in the real-time priority range. The grab loop thread is the thread that calls the RetrieveResult() method. A value of 24 or higher is recommended. Thread priorities can be adjusted using the <a class="el" href="namespace_pylon.html#ab5955fe2bfdfc50177659c49ae90e854"><code>SetRTThreadPriority</code> </a> method. The priority of the grab loop thread that is optionally provided by the Instant Camera object can be adjusted using the <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params__v6__1__0.html#afde4984a24386f79f184df8a22025c8c"><code>GrabLoopThreadPriorityOverride</code> </a> and <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params__v6__1__0.html#a234277cb10664ba17c0fb28d1e5a5b99"><code>GrabLoopThreadPriority</code> </a> parameters. </li>
<li>The internal Instant Camera grab engine thread should have its priority set to a value in the real-time priority range. A value of 25 or higher is recommended. The default priority is 25. The grab engine thread priority must be higher than the grab loop thread priority. The grab engine thread priority can be adjusted using the <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params__v6__1__0.html#adb9e713a5af6d9170957c051650e01fb"><code>InternalGrabEngineThreadPriorityOverride</code> </a> and <a class="el" href="class_basler___instant_camera_params_1_1_c_instant_camera_params___params__v6__1__0.html#a635956dab71ee9e7b3773dc2592081e7"><code>InternalGrabEngineThreadPriority</code> </a> parameters.</li>
</ul>
<dl class="section note"><dt>Note</dt><dd>When using real-time thread priorities, be very careful to ensure that no high-priority thread consumes all of the available CPU time.</dd></dl>
<h1><a class="anchor" id="programmers_guide_low_level_api"></a>
Programming Using the pylon Low Level API</h1>
<p>The Instant Camera classes use the Low Level API for operation. That means that the previous API, now called the Low Level API, is still part of the pylon C++ API and will be in the future. The Low Level API can be used for existing applications and for rare highly advanced use cases that can't be covered using the Instant Camera classes. More information about how to program using the Low Level API can be found <a class="el" href="low_level_api.html">here</a>.</p>
<h1><a class="anchor" id="migration_to_usb"></a>
Migrating Existing Code for Using SFNC 2.x-Based Camera Devices</h1>
<h2><a class="anchor" id="sfnc_parameter_name_changes"></a>
Changes of Parameter Names and Behavior</h2>
<p>Most features, e.g., Gain, are named according to the GenICam Standard Feature Naming Convention (SFNC). The SFNC defines a common set of features, their behavior, and the related parameter names. All Basler USB 3.0 and CoaXPress as well as most GigE, e.g., ace 2 GigE, cameras are based on the SFNC version 2.0 or later. Older Basler GigE camera models, however, are based on previous SFNC versions. Accordingly, the behavior of these cameras and some parameter names will be different.</p>
<p>Additionally, parameters that are not covered by the SFNC have been prefixed with Bsl for some camera models, e.g., for all ace 2 camera models. This has been done to be able to clearly distinguish these parameter names from SFNC parameter names. You can check whether a parameter or its equivalent with a Bsl prefix is available by using the <a class="el" href="group___gen_api___public_interface.html#ga9429c4373073d861a7daa9309b578dd7" title="Tests if readable. ">CParameter::IsReadable()</a>, <a class="el" href="group___gen_api___public_interface.html#ga26ed84e6fb3d3d0136c6cace6ddc0cf9" title="Tests if writable. ">CParameter::IsWritable()</a> or CParameter::IsValid() methods.</p>
<h3><a class="anchor" id="sfnc_parameter_name_changes_sfnc_version"></a>
SFNC Version Handling</h3>
<p>If your code has to work with camera devices that are based on different SFNC versions, you can use the <a class="el" href="class_pylon_1_1_c_instant_camera.html#a90d2817d90e2a6b0a2fa120666bc702a">GetSfncVersion() </a> method to handle differences in parameter name and behavior. <a class="el" href="namespace_pylon.html#a8329f950f719fcdc6bac7d6bb27e6f17">GetSfncVersion() </a> is also supplied as function for the use with legacy code using the Low Level API.</p>
<p>Example for <a class="el" href="pylon_programmingguide.html#generic_parameter_access">Generic Parameter Access</a> :</p>
<div class="fragment"><div class="line"><span class="comment">// Check to see which Standard Feature Naming Convention (SFNC) is used by the camera device.</span></div><div class="line"><span class="keywordflow">if</span> ( camera.GetSfncVersion() &gt;= Sfnc_2_0_0)</div><div class="line">{</div><div class="line">    <span class="comment">// Access the Gain float type node. This node is available for USB camera devices.</span></div><div class="line">    <span class="comment">// USB camera devices are compliant to SFNC version 2.0.</span></div><div class="line">    CFloatParameter gain(nodemap, <span class="stringliteral">&quot;Gain&quot;</span>);</div><div class="line">    gain.SetValuePercentOfRange(50.0);</div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Gain (50%)       : &quot;</span> &lt;&lt; gain.GetValue() &lt;&lt; <span class="stringliteral">&quot; (Min: &quot;</span> &lt;&lt; gain.GetMin() &lt;&lt; <span class="stringliteral">&quot;; Max: &quot;</span> &lt;&lt; gain.GetMax() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; endl;</div><div class="line">}</div><div class="line"><span class="keywordflow">else</span></div><div class="line">{</div><div class="line">    <span class="comment">// Access the GainRaw integer type node. This node is available for IIDC 1394 and GigE camera devices.</span></div><div class="line">    CIntegerParameter gainRaw(nodemap, <span class="stringliteral">&quot;GainRaw&quot;</span>);</div><div class="line">    gainRaw.SetValuePercentOfRange(50.0);</div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Gain (50%)       : &quot;</span> &lt;&lt; gainRaw.GetValue() &lt;&lt; <span class="stringliteral">&quot; (Min: &quot;</span> &lt;&lt; gainRaw.GetMin() &lt;&lt; <span class="stringliteral">&quot;; Max: &quot;</span> &lt;&lt; gainRaw.GetMax() &lt;&lt; <span class="stringliteral">&quot;; Inc: &quot;</span> &lt;&lt; gainRaw.GetInc() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; endl;</div><div class="line">}</div></div><!-- fragment --><p>Example for <a class="el" href="pylon_programmingguide.html#native_parameter_access">Native Parameter Access</a> :</p>
<div class="fragment"><div class="line"><span class="keywordflow">if</span> (camera.GetSfncVersion() &gt;= Sfnc_2_0_0) <span class="comment">// Cameras based on SFNC 2.0 or later, e.g., USB cameras</span></div><div class="line">{</div><div class="line">    camera.Gain.SetValuePercentOfRange(50.0);</div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Gain (50%)       : &quot;</span> &lt;&lt; camera.Gain.GetValue() &lt;&lt; <span class="stringliteral">&quot; (Min: &quot;</span> &lt;&lt; camera.Gain.GetMin() &lt;&lt; <span class="stringliteral">&quot;; Max: &quot;</span> &lt;&lt; camera.Gain.GetMax() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; endl;</div><div class="line">}</div><div class="line"><span class="keywordflow">else</span> </div><div class="line">{</div><div class="line">    camera.GainRaw.SetValuePercentOfRange(50.0);</div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Gain (50%)       : &quot;</span> &lt;&lt; camera.GainRaw.GetValue() &lt;&lt; <span class="stringliteral">&quot; (Min: &quot;</span> &lt;&lt; camera.GainRaw.GetMin() &lt;&lt; <span class="stringliteral">&quot;; Max: &quot;</span> &lt;&lt; camera.GainRaw.GetMax() &lt;&lt; <span class="stringliteral">&quot;; Inc: &quot;</span> &lt;&lt; camera.GainRaw.GetInc() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; endl;</div><div class="line">}</div></div><!-- fragment --><h3><a class="anchor" id="sfnc_parameter_name_changes_table"></a>
List of Changes</h3>
<p>The following tables show how to map previous parameter names to their equivalents as defined in SFNC 2.x. Some previous parameters have no direct equivalents. There are previous parameters, however, that can still be accessed using the so-called <a class="el" href="struct_gen_api_1_1_i_node.html#a914b295d26a33f00e9752ae8dde96933">alias</a>. The alias is another representation of the original parameter. Usually, the alias provides an Integer representation of a Float parameter.</p>
<p>The following code snippet shows how to get the alias:</p>
<dl class="section attention"><dt>Attention</dt><dd>Depending on the camera device model the alias does not provide a proper name, display name, tool tip, or description. The value range of an alias node can change when updating the camera firmware.</dd></dl>
<div class="fragment"><div class="line"><span class="comment">// Get the alias node of a parameter.</span></div><div class="line"><span class="comment">// The alias is another representation of the original parameter.</span></div><div class="line"><a class="code" href="class_gen_api_1_1_c_float_ptr.html">GenApi::CFloatPtr</a> gain( camera.GetNodeMap().GetNode( <span class="stringliteral">&quot;Gain&quot;</span>));</div><div class="line"><a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CIntegerPtr</a> gainRaw;</div><div class="line"><span class="keywordflow">if</span> ( gain.IsValid())</div><div class="line">{</div><div class="line">    <span class="comment">// Get the integer representation of Gain.</span></div><div class="line">    <span class="comment">// Depending on the camera device model the alias does not provide a proper name, display name, tool tip, or description.</span></div><div class="line">    <span class="comment">// The value range of an alias node can change when updating the camera firmware.</span></div><div class="line">    gainRaw = gain-&gt;GetNode()-&gt;GetAlias();</div><div class="line">}</div></div><!-- fragment --><p>The following table shows the parameters name changes:</p>
<dl class="section attention"><dt>Attention</dt><dd>The actual changes between previous cameras and SFNC 2.x-compliant cameras depend on the models and the camera firmware versions. It is possible that changes are not listed in the tables below. Other sources of information regarding changes between camera models are the camera topics in the Basler Product Documentation, camera user's manuals or the information shown in the pylon Viewer.</dd></dl>
<table  border="1" class="table" frame="void" cellspacing="6" cellpadding="7">
<tr>
<th>Previous Parameter Name </th><th>SFNC 2.x or Equivalent with Bsl Prefix </th><th>Parameter Type </th><th>Comments  </th></tr>
<tr>
<td>AcquisitionFrameCount </td><td>AcquisitionBurstFrameCount </td><td>Integer </td><td></td></tr>
<tr>
<td>AcquisitionFrameRateAbs </td><td>AcquisitionFrameRate </td><td>Float </td><td></td></tr>
<tr>
<td>AcquisitionStartEventFrameID </td><td>EventFrameBurstStartFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>AcquisitionStartEventTimestamp </td><td>EventFrameBurstStartTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>AcquisitionStartOvertriggerEventFrameID </td><td>EventFrameBurstStartOvertriggerFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>AcquisitionStartOvertriggerEventTimestamp </td><td>EventFrameBurstStartOvertriggerTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>AutoExposureTimeAbsLowerLimit </td><td>AutoExposureTimeLowerLimit </td><td>Float </td><td></td></tr>
<tr>
<td>AutoExposureTimeAbsUpperLimit </td><td>AutoExposureTimeUpperLimit </td><td>Float </td><td></td></tr>
<tr>
<td>AutoFunctionAOIUsageIntensity </td><td>AutoFunctionAOIUseBrightness </td><td>Boolean </td><td></td></tr>
<tr>
<td>AutoFunctionAOIUsageWhiteBalance </td><td>AutoFunctionAOIUseWhiteBalance </td><td>Boolean </td><td></td></tr>
<tr>
<td>AutoGainRawLowerLimit </td><td>Alias of AutoGainLowerLimit </td><td>Integer </td><td></td></tr>
<tr>
<td>AutoGainRawUpperLimit </td><td>Alias of AutoGainUpperLimit </td><td>Integer </td><td></td></tr>
<tr>
<td>AutoTargetValue </td><td>Alias of AutoTargetBrightness </td><td>Integer </td><td></td></tr>
<tr>
<td>BalanceRatioAbs </td><td>BalanceRatio </td><td>Float </td><td></td></tr>
<tr>
<td>BalanceRatioRaw </td><td>Alias of BalanceRatio </td><td>Integer </td><td></td></tr>
<tr>
<td>BlackLevelAbs </td><td>BlackLevel </td><td>Float </td><td></td></tr>
<tr>
<td>BlackLevelRaw </td><td>Alias of BlackLevel </td><td>Integer </td><td></td></tr>
<tr>
<td>ChunkExposureTimeRaw </td><td></td><td>Integer </td><td>ChunkExposureTimeRaw has been replaced with ChunkExposureTime. ChunkExposureTime is of type float.  </td></tr>
<tr>
<td>ChunkFrameCounter </td><td></td><td>Integer </td><td>ChunkFrameCounter has been replaced with ChunkCounterSelector and ChunkCounterValue.  </td></tr>
<tr>
<td>ChunkGainAll </td><td></td><td>Integer </td><td>ChunkGainAll has been replaced with ChunkGain. ChunkGain is of type float.  </td></tr>
<tr>
<td>ColorAdjustmentEnable </td><td></td><td>Boolean </td><td>ColorAdjustmentEnable has been removed. The color adjustment is always enabled.  </td></tr>
<tr>
<td>ColorAdjustmentEnable </td><td>BslColorAdjustmentEnable </td><td>Boolean </td><td></td></tr>
<tr>
<td>ColorAdjustmentHue </td><td>BslColorAdjustmentHue </td><td>Float </td><td></td></tr>
<tr>
<td>ColorAdjustmentHueRaw </td><td>Alias of ColorAdjustmentHue or BslColorAdjustmentHue </td><td>Integer </td><td></td></tr>
<tr>
<td>ColorAdjustmentReset </td><td></td><td>Command </td><td>ColorAdjustmentReset has been removed.  </td></tr>
<tr>
<td>ColorAdjustmentSaturation </td><td>BslColorAdjustmentSaturation </td><td>Float </td><td></td></tr>
<tr>
<td>ColorAdjustmentSaturationRaw </td><td>Alias of ColorAdjustmentSaturation or BslColorAdjustmentSaturation </td><td>Integer </td><td></td></tr>
<tr>
<td>ColorAdjustmentSelector </td><td>BslColorAdjustmentSelector </td><td>Enumeration </td><td></td></tr>
<tr>
<td>ColorSpace </td><td>BslColorSpace </td><td>Enumeration </td><td></td></tr>
<tr>
<td>ColorTransformationValueRaw </td><td>Alias of ColorTransformationValue </td><td>Integer </td><td></td></tr>
<tr>
<td>ContrastMode </td><td>BslContrastMode </td><td>Enumeration </td><td></td></tr>
<tr>
<td>DefaultSetSelector </td><td></td><td>Enumeration </td><td>See additional entries in UserSetSelector.  </td></tr>
<tr>
<td>ExposureEndEventFrameID </td><td>EventExposureEndFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>ExposureEndEventTimestamp </td><td>EventExposureEndTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>ExposureTimeAbs </td><td>ExposureTime </td><td>Float </td><td></td></tr>
<tr>
<td>ExposureTimeMode </td><td>BslExposureTimeMode </td><td>Enumeration </td><td></td></tr>
<tr>
<td>ExposureTimeRaw </td><td>Alias of ExposureTime </td><td>Integer </td><td></td></tr>
<tr>
<td>FrameStartEventFrameID </td><td>EventFrameStartFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>FrameStartEventTimestamp </td><td>EventFrameStartTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>FrameStartOvertriggerEventFrameID </td><td>EventFrameStartOvertriggerFrameID </td><td>Integer </td><td></td></tr>
<tr>
<td>FrameStartOvertriggerEventTimestamp </td><td>EventFrameStartOvertriggerTimestamp </td><td>Integer </td><td></td></tr>
<tr>
<td>GainAbs </td><td>Gain </td><td>Float </td><td></td></tr>
<tr>
<td>GainRaw </td><td>Alias of Gain </td><td>Integer </td><td></td></tr>
<tr>
<td>GammaEnable </td><td></td><td>Boolean </td><td>GammaEnable has been removed. Gamma is always enabled.  </td></tr>
<tr>
<td>GammaSelector </td><td></td><td>Enumeration </td><td>The sRGB setting is automatically applied when LineSourcePreset is set to any other value than Off.  </td></tr>
<tr>
<td>GevIEEE1588 </td><td>PtpEnable </td><td>Boolean </td><td></td></tr>
<tr>
<td>GevIEEE1588ClockId </td><td>PtpClockID </td><td>Integer </td><td></td></tr>
<tr>
<td>GevIEEE1588DataSetLatch </td><td>PtpDataSetLatch </td><td>Command </td><td></td></tr>
<tr>
<td>GevIEEE1588OffsetFromMaster </td><td>PtpOffsetFromMaster </td><td>Integer </td><td></td></tr>
<tr>
<td>GevIEEE1588ParentClockId </td><td>PtpParentClockID </td><td>Integer </td><td></td></tr>
<tr>
<td>GevIEEE1588Status </td><td></td><td>Enumeration </td><td>GevIEEE1588Status has been removed. Use PtpDataSetLatch and then PtpStatus instead.  </td></tr>
<tr>
<td>GevIEEE1588StatusLatched </td><td>PtpStatus </td><td>Enumeration </td><td></td></tr>
<tr>
<td>GevTimestampControlLatch </td><td>TimestampLatch </td><td>Command </td><td></td></tr>
<tr>
<td>GevTimestampControlLatchReset </td><td></td><td>Command </td><td></td></tr>
<tr>
<td>GevTimestampControlReset </td><td>TimestampReset </td><td>Command </td><td></td></tr>
<tr>
<td>GevTimestampValue </td><td>TimestampLatchValue </td><td>Integer </td><td></td></tr>
<tr>
<td>GlobalResetReleaseModeEnable </td><td></td><td>Boolean </td><td>GlobalResetReleaseModeEnable has been replaced with the enumeration ShutterMode.  </td></tr>
<tr>
<td>LightSourcePreset </td><td>BslLightSourcePreset </td><td>Enumeration </td><td></td></tr>
<tr>
<td>LightSourceSelector </td><td>LightSourcePreset </td><td>Enumeration </td><td></td></tr>
<tr>
<td>LineDebouncerTimeAbs </td><td>LineDebouncerTime </td><td>Float </td><td></td></tr>
<tr>
<td>LineOverloadStatus </td><td>BslLineOverloadStatus </td><td>Boolean </td><td></td></tr>
<tr>
<td>MinOutPulseWidthAbs </td><td>LineMinimumOutputPulseWidth </td><td>Float </td><td></td></tr>
<tr>
<td>MinOutPulseWidthRaw </td><td>Alias of LineMinimumOutputPulseWidth </td><td>Integer </td><td></td></tr>
<tr>
<td>ParameterSelector </td><td>RemoveParameterLimitSelector </td><td>Enumeration </td><td></td></tr>
<tr>
<td>ProcessedRawEnable </td><td></td><td>Boolean </td><td>ProcessedRawEnable has been removed because it is not needed anymore. The camera uses nondestructive Bayer demosaicing now.  </td></tr>
<tr>
<td>ReadoutTimeAbs </td><td>SensorReadoutTime </td><td>Float </td><td></td></tr>
<tr>
<td>ResultingFrameRateAbs </td><td>ResultingFrameRate </td><td>Float </td><td></td></tr>
<tr>
<td>SensorBitDepth </td><td>BslSensorBitDepth </td><td>Enumeration </td><td></td></tr>
<tr>
<td>SequenceAddressBitSelector </td><td></td><td>Enumeration </td><td></td></tr>
<tr>
<td>SequenceAdvanceMode </td><td></td><td>Enumeration </td><td></td></tr>
<tr>
<td>SequenceAsyncAdvance </td><td></td><td>Command </td><td>Configure a asynchronous signal as trigger source of path 1.  </td></tr>
<tr>
<td>SequenceAsyncRestart </td><td></td><td>Command </td><td>Configure a asynchronous signal as trigger source of path 0.  </td></tr>
<tr>
<td>SequenceBitSource </td><td></td><td>Enumeration </td><td></td></tr>
<tr>
<td>SequenceControlConfig </td><td></td><td>Category </td><td></td></tr>
<tr>
<td>SequenceControlSelector </td><td></td><td>Enumeration </td><td></td></tr>
<tr>
<td>SequenceControlSource </td><td></td><td>Enumeration </td><td></td></tr>
<tr>
<td>SequenceCurrentSet </td><td>SequencerSetActive </td><td>Integer </td><td></td></tr>
<tr>
<td>SequenceEnable </td><td></td><td>Boolean </td><td>Replaced by SequencerConfigurationMode and SequencerMode.  </td></tr>
<tr>
<td>SequenceSetExecutions </td><td></td><td>Integer </td><td></td></tr>
<tr>
<td>SequenceSetIndex </td><td>SequencerSetSelector </td><td>Integer </td><td></td></tr>
<tr>
<td>SequenceSetLoad </td><td>SequencerSetLoad </td><td>Command </td><td></td></tr>
<tr>
<td>SequenceSetStore </td><td>SequencerSetSave </td><td>Command </td><td></td></tr>
<tr>
<td>SequenceSetTotalNumber </td><td></td><td>Integer </td><td>Use the range of the SequencerSetSelector.  </td></tr>
<tr>
<td>TemperatureState </td><td>BslTemperatureStatus </td><td>Enumeration </td><td></td></tr>
<tr>
<td>TestImageSelector </td><td>TestPattern </td><td>Enumeration </td><td>TestPattern instead of TestImageSelector is used for dart and pulse camera models.  </td></tr>
<tr>
<td>TimerDelayAbs </td><td>TimerDelay </td><td>Float </td><td></td></tr>
<tr>
<td>TimerDelayRaw </td><td>Alias of TimerDelay </td><td>Integer </td><td></td></tr>
<tr>
<td>TimerDelayTimebaseAbs </td><td></td><td>Float </td><td>The time base is always 1us.  </td></tr>
<tr>
<td>TimerDurationAbs </td><td>TimerDuration </td><td>Float </td><td></td></tr>
<tr>
<td>TimerDurationRaw </td><td>Alias of TimerDuration </td><td>Integer </td><td></td></tr>
<tr>
<td>TimerDurationTimebaseAbs </td><td></td><td>Float </td><td>The time base is always 1us.  </td></tr>
<tr>
<td>TriggerDelayAbs </td><td>TriggerDelay </td><td>Float </td><td></td></tr>
<tr>
<td>UserSetDefaultSelector </td><td>UserSetDefault </td><td>Enumeration </td><td></td></tr>
<tr>
<td>VignettingCorrectionLoad </td><td>BslVignettingCorrectionLoad </td><td>Command </td><td></td></tr>
<tr>
<td>VignettingCorrectionMode </td><td>BslVignettingCorrectionMode </td><td>Enumeration </td><td></td></tr>
</table>
<p>The following table shows how to map changes for enumeration values:</p>
<table  border="1" class="table" frame="void" cellspacing="6" cellpadding="7">
<tr>
<th>Previous Enumeration Name </th><th>Previous Enumeration Value Name </th><th>Value Name SFNC 2.x </th><th>Comments  </th></tr>
<tr>
<td>AcquisitionStatusSelector </td><td>AcquisitionTriggerWait </td><td>FrameBurstTriggerWait </td><td></td></tr>
<tr>
<td>AutoFunctionProfile </td><td>ExposureMinimum </td><td>MinimizeExposureTime </td><td></td></tr>
<tr>
<td>AutoFunctionProfile </td><td>GainMinimum </td><td>MinimizeGain </td><td></td></tr>
<tr>
<td>ChunkSelector </td><td>GainAll </td><td>Gain </td><td>The gain value is reported via the ChunkGain node as float.  </td></tr>
<tr>
<td>ChunkSelector </td><td>Height </td><td></td><td>Height is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>OffsetX </td><td></td><td>OffsetX is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>OffsetY </td><td></td><td>OffsetY is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>PixelFormat </td><td></td><td>PixelFormat is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>Stride </td><td></td><td>Stride is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>ChunkSelector </td><td>Width </td><td></td><td>Width is part of the image information regardless of the chunk mode setting.  </td></tr>
<tr>
<td>EventNotification </td><td>GenICamEvent </td><td>On </td><td></td></tr>
<tr>
<td>EventSelector </td><td>AcquisitionStartOvertrigger </td><td>FrameBurstStartOvertrigger </td><td></td></tr>
<tr>
<td>EventSelector </td><td>AcquisitionStart </td><td>FrameBurstStart </td><td></td></tr>
<tr>
<td>LightSourceSelector </td><td>Daylight </td><td>Daylight5000K </td><td></td></tr>
<tr>
<td>LightSourceSelector </td><td>Tungsten </td><td>Tungsten2800K </td><td></td></tr>
<tr>
<td>LineSelector </td><td>Out1 </td><td></td><td>The operation mode of an I/O-Pin is chosen using the LineMode Selector.  </td></tr>
<tr>
<td>LineSelector </td><td>Out2 </td><td></td><td>The operation mode of an I/O-Pin is chosen using the LineMode Selector.  </td></tr>
<tr>
<td>LineSelector </td><td>Out3 </td><td></td><td>The operation mode of an I/O-Pin is chosen using the LineMode Selector.  </td></tr>
<tr>
<td>LineSelector </td><td>Out4 </td><td></td><td>The operation mode of an I/O-Pin is chosen using the LineMode Selector.  </td></tr>
<tr>
<td>LineSource </td><td>AcquisitionTriggerWait </td><td>FrameBurstTriggerWait </td><td></td></tr>
<tr>
<td>LineSource </td><td>UserOutput </td><td></td><td>Use UserOutput1, UserOutput2, or UserOutput3 etc. instead.  </td></tr>
<tr>
<td>PixelFormat </td><td>BayerBG12Packed </td><td></td><td>The pixel format BayerBG12p is provided by USB camera devices. The memory layout of pixel format BayerBG12Packed and pixel format BayerBG12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>BayerGB12Packed </td><td></td><td>The pixel format BayerGB12p is provided by USB camera devices. The memory layout of pixel format BayerGB12Packed and pixel format BayerGB12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>BayerGR12Packed </td><td></td><td>The pixel format BayerGR12p is provided by USB camera devices. The memory layout of pixel format BayerGR12Packed and pixel format BayerGR12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>BayerRG12Packed </td><td></td><td>The pixel format BayerRG12p is provided by USB camera devices. The memory layout of pixel format BayerRG12Packed and pixel format BayerRG12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>BGR10Packed </td><td>BGR10 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>BGR12Packed </td><td>BGR12 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>BGR8Packed </td><td>BGR8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>BGRA8Packed </td><td>BGRa8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>Mono10Packed </td><td></td><td>The pixel format Mono10p is provided by USB camera devices. The memory layout of pixel format Mono10Packed and pixel format Mono10p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>Mono12Packed </td><td></td><td>The pixel format Mono12p is provided by USB camera devices. The memory layout of pixel format Mono12Packed and pixel format Mono12p is different. See the camera User's Manuals for more information on pixel formats.  </td></tr>
<tr>
<td>PixelFormat </td><td>Mono1Packed </td><td>Mono1p </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>Mono2Packed </td><td>Mono2p </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>Mono4Packed </td><td>Mono4p </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGB10Packed </td><td>RGB10 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGB12Packed </td><td>RGB12 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGB16Packed </td><td>RGB16 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGB8Packed </td><td>RGB8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>RGBA8Packed </td><td>RGBa8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>YUV411Packed </td><td>YCbCr411_8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>YUV422_YUYV_Packed </td><td>YCbCr422_8 </td><td></td></tr>
<tr>
<td>PixelFormat </td><td>YUV444Packed </td><td>YCbCr8 </td><td></td></tr>
<tr>
<td>TestImageSelector </td><td>Testimage1 </td><td>GreyDiagonalSawtooth8 </td><td>GreyDiagonalSawtooth8 instead of Testimage1 is used for dart and pulse camera models.  </td></tr>
<tr>
<td>TriggerSelector </td><td>AcquisitionStart </td><td>FrameBurstStart </td><td></td></tr>
</table>
<h2><a class="anchor" id="sfnc_parameter_name_changes_cm"></a>
Migration Mode</h2>
<p>pylon USB and GigE devices offer a convenient migration mode that allows you to work with camera devices that are based on different SFNC versions by automatically adapting your application code accordingly. If the migration mode is enabled, the changes shown in the tables above are automatically reflected in your code where appropriate. If you are only working with SFNC 2.x-based cameras, however, Basler strongly recommends rewriting existing code to be SFNC 2.x-compliant instead of using the migration mode.</p>
<dl class="section attention"><dt>Attention</dt><dd>Existing applications may use features that can't be mapped automatically. In this case, the application code needs to adapted before it can be used with SFNC 2.x-based cameras. The behavior of a parameter may have changed as well, e.g., its value range. Check this carefully. Furthermore, automatically mapped alias nodes don't provide a proper name, display name, tooltip, or description. The value range of an alias node can change when updating the camera firmware.</dd></dl>
<div class="fragment"><div class="line"><span class="comment">// Create an instant camera object with the camera device found first.</span></div><div class="line"><a class="code" href="class_pylon_1_1_c_instant_camera.html">Pylon::CInstantCamera</a> camera( CTlFactory::GetInstance().CreateFirstDevice());</div><div class="line"></div><div class="line"><span class="comment">// Activate the migration mode if available.</span></div><div class="line"><span class="comment">// This allows existing code to work with SFNC 2.x compatible cameras</span></div><div class="line"><span class="comment">// with minimal changes, depending on the used features.</span></div><div class="line"><a class="code" href="class_gen_api_1_1_c_pointer.html">GenApi::CBooleanPtr</a> migrationModeEnable( camera.GetTLNodeMap().GetNode(<span class="stringliteral">&quot;MigrationModeEnable&quot;</span>));</div><div class="line"><span class="keywordflow">if</span> ( <a class="code" href="group___gen_api___public_interface.html#ga26ed84e6fb3d3d0136c6cace6ddc0cf9">GenApi::IsWritable</a>( migrationModeEnable))</div><div class="line">{</div><div class="line">    migrationModeEnable-&gt;SetValue( <span class="keyword">true</span>);</div><div class="line">}</div><div class="line"></div><div class="line"><span class="comment">// Open the camera.</span></div><div class="line">camera.Open();</div><div class="line"></div><div class="line"><span class="comment">// For demonstration purposes only, access ExposureTimeAbs alias ExposureTime.</span></div><div class="line"><a class="code" href="class_gen_api_1_1_c_float_ptr.html">GenApi::CFloatPtr</a> exposureTime( camera.GetNodeMap().GetNode( <span class="stringliteral">&quot;ExposureTimeAbs&quot;</span>));</div><div class="line"></div><div class="line"><span class="comment">// ExposureTime can still be accessed. The same node is returned.</span></div><div class="line"><a class="code" href="class_gen_api_1_1_c_float_ptr.html">GenApi::CFloatPtr</a> exposureTime2( camera.GetNodeMap().GetNode( <span class="stringliteral">&quot;ExposureTime&quot;</span>));</div></div><!-- fragment --><p>The migration mode is implemented using proxy objects. If the migration mode is enabled, the call to <a class="el" href="class_pylon_1_1_c_instant_camera.html#a3227195969200a52200364bf31e9c586" title="Provides access to the node map of the camera device. ">Pylon::CInstantCamera::GetNodeMap()</a> (or <a class="el" href="struct_pylon_1_1_i_pylon_device.html#a100126837d4bc3eaa74531f9b1e39bf6" title="Returns the set of camera parameters. ">Pylon::IPylonDevice::GetNodeMap()</a>) returns a proxy object that wraps the original node map. The node map proxy maps parameter changes in calls to <a class="el" href="struct_gen_api_1_1_i_node_map.html#a493d5d9c380c2bb04c03d8874f133f57" title="Retrieves the node from the central map by Name. ">GenApi::INodeMap::GetNode()</a>. All other calls are forwarded to the original node map. Enumerations having renamed enumeration values are also wrapped by a proxy, e.g. the enumeration PixelFormat. The enumeration proxy maps value name changes in the calls <a class="el" href="struct_gen_api_1_1_i_value.html#aa4a55b401c2fefdac0a1d2971e772060" title="Get content of the node as string. ">GenApi::IValue::ToString()</a>, <a class="el" href="struct_gen_api_1_1_i_value.html#ae72e703a7e51f62f4886d304256d8ab1" title="Set content of the node as string. ">GenApi::IValue::FromString()</a>, and <a class="el" href="struct_gen_api_1_1_i_enumeration.html#a78a0a3b20de1c854648b16268dddbf1b" title="Get an entry node by name. ">GenApi::IEnumeration::GetEntryByName()</a>. All other calls are forwarded to the original enumeration node.</p>
<h2><a class="anchor" id="usb_changes_transport"></a>
Differences in Image Transport</h2>
<p>The image transport on USB camera devices differs from the image transport on GigE camera devices. GigE camera devices automatically send image data to the computer when available. If the computer is not ready to receive the image data because no grab buffer is available, the image data sent by the camera device is dropped. For USB camera devices, the computer has to actively request the image data. Grabbed images are stored in the frame buffer of the USB camera device until the computer requests the image data. If the frame buffer of the USB camera device is full, newly acquired frames will be dropped. Old images in the frame buffer of the USB camera device will be grabbed first when the computer requests image data again. After that, newly acquired images are grabbed.</p>
<h2><a class="anchor" id="usb_strategy_upcoming_image_not_available"></a>
The Grab Strategy Upcoming Image is Not Available For USB Camera Devices</h2>
<p>The Upcoming Image grab strategy utilizes the effect that images are automatically dropped if no buffer is available (queued) on the computer when using GigE cameras. USB camera devices work differently as described above. Old images can still be stored in the frame buffer of the USB camera device. That's why the Upcoming Image strategy can't be used for USB camera devices. An exception will be thrown, if a USB camera device is used together with the Upcoming Image grab strategy.</p>
<h2><a class="anchor" id="usb_and_counters"></a>
USB Camera Devices and Block ID</h2>
<p>Image data is transferred between a computer and a USB camera device using a certain sequence of data packets. In the rare case of an error during the image transport, the image data stream between computer and USB camera device is reset automatically, e.g., if the image packet sequence is out of sync. The image data stream reset causes the Block ID delivered by the USB camera device to start again at zero. Pylon indicates this error condition by setting the <a class="el" href="class_pylon_1_1_c_grab_result_data.html#ae26269c7f9c2c848dad24eea33fed0fd">Block ID </a> of the grab result to its highest possible value (UINT64_MAX) for all subsequent grab results. A Block ID of UINT64_MAX is invalid and can't be used in any further operations. The image data and other grab result data are not affected by the Block ID being invalid. The grabbing needs to be <a class="el" href="class_pylon_1_1_c_instant_camera.html#a5ef34cbfa61d4f0c2c1739bea5e5ee4f">stopped </a> and <a class="el" href="class_pylon_1_1_c_instant_camera.html#a386b84c29f9ee7ec3646fbfbf70236ed">restarted </a> to recover from this error condition if the application uses the Block ID. The Block ID starts at zero if the grabbing is restarted.</p>
<dl class="section note"><dt>Note</dt><dd>Applications that are still using the Low Level API can use the <a class="el" href="struct_pylon_1_1_i_stream_grabber.html#acbd70617e6289a1139fc407a2d8d56a9" title="Cancels grabbing the current buffer and flushes all buffers to the output queue. ">Pylon::IStreamGrabber::FlushBuffersToOutput</a> method. Calling FlushBuffersToOutput resets the image stream between computer and USB camera device, too. Therefore, the value of the Block ID is set to UINT64_MAX for all subsequent grab results after calling FlushBuffersToOutput.</dd></dl>
<h1><a class="anchor" id="camemu_tl"></a>
Camera Emulator</h1>
<p>pylon offers a camera emulation transport layer, which is similar to other transport layers. The camera emulator transport layer can create simple camera emulator devices that allow you to develop applications without having a physical camera device attached to your computer. The emulator's functionality is limited, but it is able to create test images for different bit depths.</p>
<p>The number of available emulator devices can be controlled by setting the &lt;PYLON_CAMEMU&gt; environment variable.</p>
<p>Example: </p><div class="fragment"><div class="line">PYLON_CAMEMU=2</div></div><!-- fragment --><p>This will provide two emulator devices. These devices can be accessed using the pylon API and the pylon Viewer program.</p>
<p>When &lt;PYLON_CAMEMU&gt; is not set, no emulator devices are provided.</p>
<dl class="section note"><dt>Note</dt><dd>A maximum of 256 emulator devices are supported.</dd></dl>
<h1><a class="anchor" id="decompression"></a>
Image Decompression</h1>
<p>For images that have been compressed using the Basler Compression Beyond feature, pylon offers the <a class="el" href="class_pylon_1_1_c_image_decompressor.html">CImageDecompressor</a> class. This class provides convenient access to cameras with compression (for reading compression statuses and settings) as well as information about grab buffers/results (with compressed images). It can also be used to decompress compressed images.</p>
<p>To understand the usage of this class, it is important to know how decompression has been implemented in pylon. At the moment, pylon will not decompress images transparently while grabbing. Therefore, the compressed grab buffers/results are provided to the user just like uncompressed ones would be. You can determine whether compression is enabled in the camera using the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a06851777482b79a36e73e0d82005e94a">GetCompressionMode()</a> method. If compression is enabled, the images can be decompressed or stored for later decompression. In both cases, a compression descriptor is required for decompression. This also means that this compression descriptor must also be stored if you want to be able to decompress the images at a later stage.</p>
<p>The content of a compression descriptor depends on various parameters of the camera (e.g., PixelFormat or ImageCompressionMode). Therefore, the camera itself will provide the compression descriptor that is required for decompression. The compression descriptor will not change while the camera is grabbing images. If the camera's parameter settings have changed, however, you must download the compression descriptor before starting image grabbing and initialize the decompressor with the downloaded compression descriptor. This is important because changing camera parameters may cause the compression descriptor to change. For that, the constructors of <a class="el" href="class_pylon_1_1_c_image_decompressor.html">CImageDecompressor</a> and the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a06d49990879a064c446035f17ce5f9ad">SetCompressionDescriptor()</a> methods can be used. You can use the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#aef714d81f4930f67d4135a95b0b30cc8">HasCompressionDescriptor()</a> method in order to find out whether a decompressor has been initialized with a compression descriptor. Furthermore, the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a9d9747d5b8d0d944ca1e6f19f857ee5f">GetCompressionDescriptor()</a> methods can be used to get the currently set compression descriptor from a decompressor instance or to download it from a camera (via its node map) for later use.</p>
<p>Every compression descriptor has a hash that can be used for comparison purposes to check whether a particular compressed image was compressed with this descriptor. You can use the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a397dc36e828f3af993e94b08afc4c5e5">ComputeCompressionDescriptorHash()</a> method to compute the hash of a given compression descriptor. On the other hand, the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#ae05408e6265165e2dc331ffee0cf640d">GetCompressionDescriptorHash()</a> methods can be used to get the hash of the compression descriptor that is currently set in a decompressor instance, from a camera (via its node map), or from a particular grab buffer/result.</p>
<p>The <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a21a4322e230f17b685dc84298317769e">GetCompressionInfo()</a> methods allow you to get compression information about a grab buffer/result. This is only possible with grab buffers/results that have been received successfully. If a grab buffer/result does not contain compression information, these methods will return false. Otherwise, they return true and provide the information via the <a class="el" href="struct_pylon_1_1_compression_info__t.html">CompressionInfo_t</a> struct. You must then check the <a class="el" href="struct_pylon_1_1_compression_info__t.html#ad53642b11b321e1abdf9b7e52cf4f11f">hasCompressedImage</a> field in the struct to find out if the grab buffer/result still contains an image that can be decompressed or if it has already been decompressed (e.g., by the transport layer; however, this is not supported by pylon yet). Then, you must check the <a class="el" href="struct_pylon_1_1_compression_info__t.html#a501903833eb6f9c345d2c3348e058e9d">compressionStatus</a> field to make sure that the camera was able to compress the image properly (it may fail if the amount of data required for compressing an image exceeds the desired compression ratio). The image can be decompressed if the <a class="el" href="struct_pylon_1_1_compression_info__t.html#a501903833eb6f9c345d2c3348e058e9d">compressionStatus</a> field is <a class="el" href="namespace_pylon.html#a387447e9e1a48407b27aa78b1b8b506ba39672260d5808ecd69987b6e64508b52">CompressionStatus_Ok</a>.</p>
<p>Finally, a grab buffer/result can be decompressed using one of the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a045eefd288f4f8e69d75f3e59d241bdd">DecompressImage()</a> methods. Only grab buffers/results which have been received successfully can be decompressed. If you want to determine the buffer size to allocate memory for the uncompressed images during streaming you can use the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a2ae8607a4ed37bb9b214adbb4d2902d8">GetImageSizeForDecompression()</a> method before starting image grabbing. Instead, you could also use the <a class="el" href="struct_pylon_1_1_compression_info__t.html#abb5b1cb73e36f12d6afd0301c704505c">decompressedImageSize</a> field to find out the image buffer size required for decompressing a particular grab buffer/result.</p>
<p>To enable compression in the camera, set the <code>ImageCompressionMode</code> parameter to <code>BaslerCompressionBeyond</code>. Further information regarding this feature, additional compression settings and their usage can be found in the Basler Product Documentation.</p>
<p>To acquire compressed images:</p><ol type="1">
<li>Enable compression in the camera using the <code>ImageCompressionMode</code> parameter.</li>
<li>Initialize the decompressor with the compression descriptor (e.g., using the camera's node map).</li>
<li>Grab image.</li>
<li>Check if grab result is successful using the <a class="el" href="class_pylon_1_1_c_grab_result_data.html#a57fbc04cd2abf3bf6307e07131dd0503">GrabSucceeded()</a> method.</li>
<li>Get compression info using the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a21a4322e230f17b685dc84298317769e">GetCompressionInfo()</a> method (returns true if grab result contains compression info).</li>
<li>Check whether grab result still contains a compressed image using the <a class="el" href="struct_pylon_1_1_compression_info__t.html#ad53642b11b321e1abdf9b7e52cf4f11f">hasCompressedImage</a> field. This step can be skipped if you are sure that the grab result contains compressed image data.</li>
<li>Check whether image was compressed successfully using the <a class="el" href="struct_pylon_1_1_compression_info__t.html#a501903833eb6f9c345d2c3348e058e9d">compressionStatus</a> field.</li>
<li>Decompress image using the <a class="el" href="class_pylon_1_1_c_image_decompressor.html#a045eefd288f4f8e69d75f3e59d241bdd">DecompressImage()</a> method.</li>
</ol>
<p>These steps are illustrated in this following sample: </p><div class="fragment"><div class="line"><span class="comment">// Set the compression mode to BaslerCompressionBeyond if available.</span></div><div class="line"><span class="keywordflow">if</span> (camera.ImageCompressionMode.CanSetValue( ImageCompressionMode_BaslerCompressionBeyond ))</div><div class="line">{</div><div class="line">    camera.ImageCompressionMode.SetValue( ImageCompressionMode_BaslerCompressionBeyond );</div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;New compression mode: &quot;</span> &lt;&lt; camera.ImageCompressionMode.ToString() &lt;&lt; endl;</div><div class="line">}</div><div class="line"><span class="comment">// Create the decompressor and initialize it with the nodemap of the camera.</span></div><div class="line">CImageDecompressor decompressor( nodemap );</div><div class="line"></div><div class="line"><span class="comment">// Wait for a new image.</span></div><div class="line"><span class="keywordflow">if</span> (camera.GrabOne( 1000, ptrGrabResult ))</div><div class="line">{</div><div class="line">    <span class="keywordflow">if</span> (ptrGrabResult-&gt;GrabSucceeded())</div><div class="line">    {</div><div class="line">        <span class="comment">// Fetch compression info and check whether the image was compressed by the camera.</span></div><div class="line">        CompressionInfo_t info;</div><div class="line">        <span class="keywordflow">if</span> (decompressor.GetCompressionInfo( info, ptrGrabResult ))</div><div class="line">        {</div><div class="line">            <span class="comment">// Print content of CompressionInfo_t.</span></div><div class="line">            printCompressionInfo( info );</div><div class="line"></div><div class="line">            <span class="comment">// Check if image is still compressed (could have been decompressed by a transport layer).</span></div><div class="line">            <span class="keywordflow">if</span> (info.hasCompressedImage)</div><div class="line">            {</div><div class="line">                <span class="keywordflow">if</span> (info.compressionStatus == <a class="code" href="namespace_pylon.html#a387447e9e1a48407b27aa78b1b8b506ba39672260d5808ecd69987b6e64508b52">CompressionStatus_Ok</a>)</div><div class="line">                {</div><div class="line">                    <span class="comment">// Show compression ratio.</span></div><div class="line">                    cout &lt;&lt; endl &lt;&lt; <span class="stringliteral">&quot;Transferred payload \t:&quot;</span> &lt;&lt; ptrGrabResult-&gt;GetPayloadSize() &lt;&lt; endl;</div><div class="line">                    cout &lt;&lt; <span class="stringliteral">&quot;Compression ratio \t:&quot;</span> &lt;&lt; (<span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(ptrGrabResult-&gt;GetPayloadSize()) / static_cast&lt;float&gt;(info.decompressedPayloadSize) * 100.0f) &lt;&lt; <span class="stringliteral">&quot;%&quot;</span> &lt;&lt; endl;</div><div class="line"></div><div class="line">                    <span class="comment">// Decompress the image.</span></div><div class="line">                    decompressor.DecompressImage( targetImage, ptrGrabResult );</div><div class="line"></div><div class="line">                    <span class="comment">// Show the image.</span></div><div class="line">                    ShowImage( targetImage, <span class="stringliteral">&quot;Decompressed image.&quot;</span> );</div><div class="line">                }</div><div class="line">                <span class="keywordflow">else</span></div><div class="line">                {</div><div class="line">                    cout &lt;&lt; <span class="stringliteral">&quot;There was an error while the camera was compressing the image.&quot;</span> &lt;&lt; endl;</div><div class="line">                }</div><div class="line">            }</div><div class="line">            <span class="keywordflow">else</span></div><div class="line">            {</div><div class="line">                <span class="comment">// No decompression is needed because it is already an uncompressed image.</span></div><div class="line">                <span class="comment">// (This can happen if the transport layer supports transparent decompressing.)</span></div><div class="line">                ShowImage( ptrGrabResult, <span class="stringliteral">&quot;Grabbed image.&quot;</span> );</div><div class="line">            }</div><div class="line">        }</div><div class="line">        <span class="keywordflow">else</span></div><div class="line">        {</div><div class="line">            <span class="comment">// No decompression is required because the image has never been compressed.</span></div><div class="line">            <span class="comment">// (This can happen if compression was accidentally turned off after initializing the decompressor class.)</span></div><div class="line">            ShowImage( ptrGrabResult, <span class="stringliteral">&quot;Grabbed image.&quot;</span> );</div><div class="line">        }</div><div class="line">    }</div><div class="line">    <span class="keywordflow">else</span></div><div class="line">    {</div><div class="line">        cout &lt;&lt; <span class="stringliteral">&quot;Error: &quot;</span> &lt;&lt; ptrGrabResult-&gt;GetErrorCode() &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; ptrGrabResult-&gt;GetErrorDescription() &lt;&lt; endl;</div><div class="line">    }</div><div class="line">}</div><div class="line"><span class="keywordflow">else</span></div><div class="line">{</div><div class="line">    cout &lt;&lt; <span class="stringliteral">&quot;Error: Could not grab an image.&quot;</span> &lt;&lt; endl;</div><div class="line">}</div></div><!-- fragment --> </div></div><!-- contents -->
<hr>
<div id="projectname">pylon <span id="projectnumber">6.1.0</span></div>
<address><small>Copyright (c) 2006-2020 <a href="http://www.baslerweb.com/">Basler AG</a>   (Mon Mar 16 2020 10:56:52)</small></address>
</body>
</html>
