%YAML:1.0
# This file is part of OpenCV project.
# It is subject to the license terms in the LICENSE file found in the top-level directory
# of this distribution and at http://opencv.org/license.html.
#
# Copyright (C) 2017, Intel Corporation, all rights reserved.
# Third party copyrights are property of their respective owners.

# Halide scheduling directives for Inception-5h architecture.

patterns:
  stripe_vec_16:
    reorder: [x, c, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 16 }
  stripe_vec_8:
    reorder: [x, c, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 8 }
  stripe_vec_4:
    reorder: [x, c, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 4 }
  fully_connected:
    split: { c: 8 }
    fuse: { src: [x, y, co], dst: block }
    parallel: block
    vectorize: { ci: 8 }

scheduling:
  # Conv+ReLU, kernel: 7x7, stride: 2x2, pad: 2x2 => 64x112x112
  conv2d0:
    pattern: stripe_vec_16
  conv2d0_pre_relu/conv_constant_exterior:
    compute_at: { conv2d0: yi }
  # MaxPool, kernel: 3x3, stride: 2x2, pad: 0x0 => 64x56x56
  maxpool0:
    pattern: stripe_vec_8
  # LRN, local_size: 11 => 64x56x56
  localresponsenorm0:
    pattern: stripe_vec_8

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0 => 64x56x56
  conv2d1:
    pattern: stripe_vec_16
  conv2d1_pre_relu/conv_constant_exterior:
    compute_at: { conv2d1: yi }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1 => 192x56x56
  conv2d2:
    pattern: stripe_vec_16
  conv2d2_pre_relu/conv_constant_exterior:
    compute_at: { conv2d2: yi }
  # LRN, local_size: 11 => 192x56x56
  localresponsenorm1:
    pattern: stripe_vec_8
  # MaxPool, kernel: 3x3, stride: 2x2, pad: 0x0 => 192x28x28
  maxpool1:
    pattern: stripe_vec_16

  # Block 1.
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 192x28x28 => 64x28x28
  mixed3a_1x1:
    pattern: stripe_vec_16
  mixed3a_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed3a_1x1: yi }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 192x28x28 => 96x28x28
  mixed3a_3x3_bottleneck:
    pattern: stripe_vec_16
  mixed3a_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed3a_3x3_bottleneck: yi }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 96x28x28 => 128x28x28
  mixed3a_3x3:
    pattern: stripe_vec_16
  mixed3a_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed3a_3x3: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 192x28x28 => 16x28x28
  mixed3a_5x5_bottleneck:
    pattern: stripe_vec_16
  mixed3a_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed3a_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 5x5, stride: 1x1, pad: 2x2, 16x28x28 => 32x28x28
  mixed3a_5x5:
    pattern: stripe_vec_16
  mixed3a_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed3a_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 192x28x28
  mixed3a_pool:
    pattern: stripe_vec_16
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 192x28x28 => 32x28x28
  mixed3a_pool_reduce:
    pattern: stripe_vec_16
  mixed3a_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed3a_pool_reduce: yi }
  # Concat: 64, 128, 32, 32 channels
  mixed3a:
    pattern: stripe_vec_16

  # Block 2.
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 256x28x28 => 128x28x28
  mixed3b_1x1:
    pattern: stripe_vec_16
  mixed3b_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed3b_1x1: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 256x28x28 => 128x28x28
  mixed3b_3x3_bottleneck:
    pattern: stripe_vec_16
  mixed3b_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed3b_3x3_bottleneck: yi }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 128x28x28 => 192x28x28
  mixed3b_3x3:
    pattern: stripe_vec_16
  mixed3b_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed3b_3x3: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 256x28x28 => 32x28x28
  mixed3b_5x5_bottleneck:
    pattern: stripe_vec_16
  mixed3b_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed3b_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 5x5, stride: 1x1, pad: 2x2, 32x28x28 => 96x28x28
  mixed3b_5x5:
    pattern: stripe_vec_16
  mixed3b_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed3b_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 256x28x28
  mixed3b_pool:
    pattern: stripe_vec_16
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 256x28x28 => 64x28x28
  mixed3b_pool_reduce:
    pattern: stripe_vec_16
  mixed3b_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed3b_pool_reduce: yi }
  # Concat: 128, 192, 96, 96 channels
  mixed3b:
    pattern: stripe_vec_16

  # Block 3.
  # MaxPool, kernel: 3x3, stride: 2x2, pad: 0x0 => 480x14x14
  maxpool4:
    reorder: [x, y, c]
    split: { c: 32 }
    parallel: co
    vectorize: { x: 8 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 480x14x14 => 192x14x14
  mixed4a_1x1:
    pattern: stripe_vec_8
  mixed4a_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed4a_1x1: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 480x14x14 => 96x14x14
  mixed4a_3x3_bottleneck:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 8 }
  mixed4a_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4a_3x3_bottleneck: yi }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 96x14x14 => 204x14x14
  mixed4a_3x3:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 8 }
  mixed4a_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed4a_3x3: yi }

  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 480x14x14 => 16x14x14
  mixed4a_5x5_bottleneck:
    pattern: stripe_vec_8
  mixed4a_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4a_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 5x5, stride: 1x1, pad: 2x2, 16x14x14 => 48x14x14
  mixed4a_5x5:
    pattern: stripe_vec_8
  mixed4a_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed4a_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 480x14x14
  mixed4a_pool:
    reorder: [x, y, c]
    split: { c: 32 }
    parallel: co
    vectorize: { x: 8 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 480x14x14 => 64x14x14
  mixed4a_pool_reduce:
    pattern: stripe_vec_8
  mixed4a_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed4a_pool_reduce: yi }
  # Concat: 192, 204, 48, 64 channels
  mixed4a:
    pattern: stripe_vec_8

  # Block 4.
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 508x14x14 => 160x14x14
  mixed4b_1x1:
    pattern: stripe_vec_8
  mixed4b_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed4b_1x1: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 508x14x14 => 112x14x14
  mixed4b_3x3_bottleneck:
    pattern: stripe_vec_8
  mixed4b_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4b_3x3_bottleneck: yi }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 112x14x14 => 224x14x14
  mixed4b_3x3:
    pattern: stripe_vec_8
  mixed4b_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed4b_3x3: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 508x14x14 => 24x14x14
  mixed4b_5x5_bottleneck:
    pattern: stripe_vec_8
  mixed4b_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4b_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 5x5, stride: 1x1, pad: 2x2, 24x14x14 => 64x14x14
  mixed4b_5x5:
    pattern: stripe_vec_8
  mixed4b_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed4b_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 508x14x14
  mixed4b_pool:
    reorder: [x, y, c]
    split: { c: 32 }
    parallel: co
    vectorize: { x: 8 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 508x14x14 => 64x14x14
  mixed4b_pool_reduce:
    pattern: stripe_vec_8
  mixed4b_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed4b_pool_reduce: yi }
  # Concat: 160, 224, 64, 64 channels
  mixed4b:
    pattern: stripe_vec_8

  # Block 5.
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 512x14x14 => 128x14x14
  mixed4c_1x1:
    pattern: stripe_vec_8
  mixed4c_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed4c_1x1: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 512x14x14 => 128x14x14
  mixed4c_3x3_bottleneck:
    pattern: stripe_vec_8
  mixed4c_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4c_3x3_bottleneck: yi }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 128x14x14 => 256x14x14
  mixed4c_3x3:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 8 }
  mixed4c_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed4c_3x3: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 1x1, 512x14x14 => 24x14x14
  mixed4c_5x5_bottleneck:
    pattern: stripe_vec_8
  mixed4c_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4c_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 5x5, stride: 1x1, pad: 2x2, 24x14x14 => 64x14x14
  mixed4c_5x5:
    pattern: stripe_vec_8
  mixed4c_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed4c_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 512x14x14
  mixed4c_pool:
    reorder: [x, y, c]
    split: { c: 32 }
    parallel: co
    vectorize: { x: 8 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 512x14x14 => 64x14x14
  mixed4c_pool_reduce:
    pattern: stripe_vec_8
  mixed4c_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed4c_pool_reduce: yi }
  # Concat: 160, 224, 64, 64 channels
  mixed4c:
    pattern: stripe_vec_8

  # Block 6.
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 512x14x14 => 112x14x14
  mixed4d_1x1:
    pattern: stripe_vec_8
  mixed4d_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed4d_1x1: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 512x14x14 => 144x14x14
  mixed4d_3x3_bottleneck:
    pattern: stripe_vec_8
  mixed4d_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4d_3x3_bottleneck: yi }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 144x14x14 => 288x14x14
  mixed4d_3x3:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 8 }
  mixed4d_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed4d_3x3: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 512x14x14 => 32x14x14
  mixed4d_5x5_bottleneck:
    pattern: stripe_vec_8
  mixed4d_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4d_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 5x5, stride: 1x1, pad: 2x2, 32x14x14 => 64x14x14
  mixed4d_5x5:
    pattern: stripe_vec_8
  mixed4d_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed4d_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 512x14x14
  mixed4d_pool:
    reorder: [x, y, c]
    split: { c: 32 }
    parallel: co
    vectorize: { x: 8 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 512x14x14 => 64x14x14
  mixed4d_pool_reduce:
    pattern: stripe_vec_8
  mixed4d_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed4d_pool_reduce: yi }
  # Concat: 112, 288, 64, 64 channels
  mixed4d:
    pattern: stripe_vec_8

  # Block 7.
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 528x14x14 => 256x14x14
  mixed4e_1x1:
    pattern: stripe_vec_8
  mixed4e_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed4e_1x1: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 528x14x14 => 160x14x14
  mixed4e_3x3_bottleneck:
    pattern: stripe_vec_8
  mixed4e_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4e_3x3_bottleneck: yi }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 160x14x14 => 320x14x14
  mixed4e_3x3:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 8 }
  mixed4e_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed4e_3x3: yi }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 528x14x14 => 32x14x14
  mixed4e_5x5_bottleneck:
    pattern: stripe_vec_8
  mixed4e_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed4e_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 32x14x14 => 128x14x14
  mixed4e_5x5:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 8 }
  mixed4e_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed4e_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 528x14x14
  mixed4e_pool:
    reorder: [x, y, c]
    split: { c: 16 }
    parallel: co
    vectorize: { x: 8 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 528x14x14 => 128x14x14
  mixed4e_pool_reduce:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 8 }
  mixed4e_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed4e_pool_reduce: yi }
  # Concat: 256, 320, 128, 128 channels
  mixed4e:
    pattern: stripe_vec_8

  # Block 8.
  # MaxPool, kernel: 3x3, stride: 2x2, pad: 0x0 => 832x7x7
  maxpool10:
    reorder: [x, c, y]
    split: { y: 2, c: 16 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 832x7x7 => 256x7x7
  mixed5a_1x1:
    reorder: [c, x, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 7 }
  mixed5a_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed5a_1x1: c }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 832x7x7 => 160x7x7
  mixed5a_3x3_bottleneck:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  mixed5a_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed5a_3x3_bottleneck: co }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 160x7x7 => 320x7x7
  mixed5a_3x3:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  mixed5a_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed5a_3x3: co }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 832x7x7 => 48x7x7
  mixed5a_5x5_bottleneck:
    reorder: [c, x, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 7 }
  mixed5a_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed5a_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 5x5, stride: 1x1, pad: 2x2, 48x7x7 => 128x7x7
  mixed5a_5x5:
    reorder: [c, x, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 7 }
  mixed5a_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed5a_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 832x7x7
  mixed5a_pool:
    reorder: [x, c, y]
    split: { y: 2, c: 16 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 832x7x7 => 128x7x7
  mixed5a_pool_reduce:
    reorder: [x, c, y]
    split: { y: 2, c: 16 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  mixed5a_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed5a_pool_reduce: yi }
  # Concat: 256, 320, 128, 128 channels
  mixed5a:
    pattern: stripe_vec_4

  # Block 9.
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 832x7x7 => 384x7x7
  mixed5b_1x1:
    reorder: [c, x, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 7 }
  mixed5b_1x1_pre_relu/conv_constant_exterior:
    compute_at: { mixed5b_1x1: c }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 832x7x7 => 192x7x7
  mixed5b_3x3_bottleneck:
    reorder: [x, c, y]
    split: { y: 2, c: 8 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  mixed5b_3x3_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed5b_3x3_bottleneck: co }
  # Conv+ReLU, kernel: 3x3, stride: 1x1, pad: 1x1, 192x7x7 => 384x7x7
  mixed5b_3x3:
    reorder: [x, c, y]
    split: { y: 2, c: 16 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  mixed5b_3x3_pre_relu/conv_constant_exterior:
    compute_at: { mixed5b_3x3: co }

  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 832x7x7 => 48x7x7
  mixed5b_5x5_bottleneck:
    reorder: [c, x, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 7 }
  mixed5b_5x5_bottleneck_pre_relu/conv_constant_exterior:
    compute_at: { mixed5b_5x5_bottleneck: yi }
  # Conv+ReLU, kernel: 5x5, stride: 1x1, pad: 2x2, 48x7x7 => 128x7x7
  mixed5b_5x5:
    reorder: [c, x, y]
    split: { y: 2 }
    parallel: yo
    unroll: yi
    vectorize: { x: 7 }
  mixed5b_5x5_pre_relu/conv_constant_exterior:
    compute_at: { mixed5b_5x5: yi }

  # MaxPool, kernel: 3x3, stride: 1x1, pad: 1x1 => 832x7x7
  mixed5b_pool:
    reorder: [x, c, y]
    split: { y: 2, c: 16 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  # Conv+ReLU, kernel: 1x1, stride: 1x1, pad: 0x0, 832x7x7 => 128x7x7
  mixed5b_pool_reduce:
    reorder: [x, c, y]
    split: { y: 2, c: 16 }
    parallel: [yo, co]
    unroll: yi
    vectorize: { x: 7 }
  mixed5b_pool_reduce_pre_relu/conv_constant_exterior:
    compute_at: { mixed5b_pool_reduce: yi }
  # Concat: 384, 384, 128, 128 channels
  mixed5b:
    pattern: stripe_vec_4

  # AvePooling => 1024x1x1
  avgpool0:
    split: { c: 16 }
    fuse: { src: [x, y, co], dst: block }
    parallel: block
    vectorize: { ci: 16 }

  # FC, 1024x1x1 => 1008x1x1
  softmax2_pre_activation/matmul:
    pattern: fully_connected

  # SoftMax, 1008x1x1 => 1008x1x1
  softmax2:
    pattern: fully_connected
